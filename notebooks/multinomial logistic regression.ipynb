{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from ortho_lib3_Copy2 import *\n",
    "\n",
    "filename = '../Pickle/def_exercises_sliced_transformed_data_all_categories.pickle'\n",
    "data_dir = '..//sliced_transformed_data/'\n",
    "category = ['Category_1', 'Category_2', 'Category_3', 'Category_4']\n",
    "extype = ['AB', 'AF', 'RF', 'EL']\n",
    "\n",
    "try:\n",
    "    all_exercises = Exercises.load(filename)\n",
    "except:\n",
    "    dffs = create_dfframes(category, extype = extype, data_dir = data_dir, print_errors=False)\n",
    "    all_exercises = dffs_to_exercises(dffs)\n",
    "    all_exercises.dump(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate functions\n",
    "\n",
    "Below are class- and function definitions for multivariate logistic regression in combination with the OR-ensemble method.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RepeatedStratifiedKFold, RepeatedKFold, KFold, LeaveOneOut, ShuffleSplit\n",
    "from sklearn.metrics import multilabel_confusion_matrix\n",
    "from itertools import groupby as g\n",
    "\n",
    "class MultivariableExperiment(Experiment):\n",
    "    \n",
    "    def __init__(self, exercises, cols = None, class_weight=None):\n",
    "        self.exercises = exercises\n",
    "        self.df = exercises.df\n",
    "        if cols is None:\n",
    "            self.cols = self.df.columns\n",
    "        else:\n",
    "            self.cols = cols\n",
    "            self.df = self.df[cols]\n",
    "        \n",
    "        # y values are category numbers\n",
    "        self.y = [int(c[-1]) for c in exercises.y]\n",
    "        self.ids = exercises.patients\n",
    "    \n",
    "    def keep_inliers(self, X, y, factor=1.1):\n",
    "        X0 = X[y == 0]\n",
    "        mean0 = np.mean(X0)\n",
    "        if np.mean(X[y == 1]) < mean0:\n",
    "            min0 = mean0 - factor * max(mean0 - X0)\n",
    "            keep = ((y == 0)|(X < min0 ).flatten())\n",
    "        else:\n",
    "            max0 = mean0 + factor * max(X0 - mean0)\n",
    "            keep = ((y == 0)|(X > max0).flatten())\n",
    "        return X[keep], y[keep]\n",
    "    \n",
    "    def fit(self, X_train, y_train):\n",
    "        \"\"\"\n",
    "        Fit a model using multinomial logistic regression.\n",
    "        \"\"\"\n",
    "        model = LogisticRegression(multi_class='multinomial', solver='saga', penalty='l2', max_iter=10000)\n",
    "        model.fit(X_train, y_train)\n",
    "        return model\n",
    "    \n",
    "    def fit_predict(self, X_train, y_train, X_valid):\n",
    "        model = self.fit(X_train, y_train)\n",
    "        return model.predict(X_valid)\n",
    "    \n",
    "    def fit_predict_p(self, X_train, y_train, X_valid):\n",
    "        model = self.fit(X_train, y_train)\n",
    "        return model.predict_proba(X_valid)\n",
    "\n",
    "    \n",
    "class MultivariableResults(Results):\n",
    "    \n",
    "    def store(self, p_id, feature, tp, tn, fp, fn):\n",
    "        \"\"\"\n",
    "        todo: Add category number?\n",
    "        \"\"\"\n",
    "        self[(p_id, feature)] = {'tp': tp, 'tn': tn, 'fp': fp, 'fn': fn }\n",
    "        \n",
    "    def score(self, fs, y_valid, y_pred):\n",
    "        \"\"\"\n",
    "        Score the predictions for multinomial logistic regression.\n",
    "        \n",
    "        This method aggregates the results per category to a single confusion matrix.\n",
    "        \"\"\"\n",
    "        y_valid = np.array(y_valid)\n",
    "        y_pred = np.array(y_pred)\n",
    "        all_patients = np.array(exp.exercises.patients)\n",
    "        \n",
    "        cats = sorted(exp.exercises.categories)\n",
    "        tp = []\n",
    "        tn = []\n",
    "        fp = []\n",
    "        fn = []\n",
    "        # iterate over categories\n",
    "        for cat in cats:\n",
    "            c = int(cat[-1])\n",
    "            exs = exp.exercises.select_category(c)\n",
    "            # get the y values for the patients in the current category\n",
    "            y_cat_valid = y_valid[np.isin(all_patients, np.array(exs.patients))]\n",
    "            y_cat_pred = y_pred[np.isin(all_patients, np.array(exs.patients))]\n",
    "            \n",
    "            # aggregate the confusion matrix with previous results\n",
    "            tp = tp + list((y_cat_valid == c) & (y_cat_pred == c))\n",
    "            tn = tn + list((y_cat_valid != c) & (y_cat_pred != c))\n",
    "            fp = fp + list((y_cat_valid != c) & (y_cat_pred == c))\n",
    "            fn = fn + list((y_cat_valid == c) & (y_cat_pred != c))\n",
    "            \n",
    "        # store the results to the Results object\n",
    "        for id, *p in zip(self.exercises.patients, tp, tn, fp, fn):\n",
    "            self.store( id, str(fs), *p)\n",
    "\n",
    "    def score_per_category(self, fs, y_valid, y_pred):\n",
    "        \"\"\"\n",
    "        Score the predictions for multinomial logistic regression.\n",
    "        \n",
    "        This method *should* create a confusion matrix per category label.\n",
    "        \"\"\"\n",
    "        y_valid = np.array(y_valid)\n",
    "        y_pred = np.array(y_pred)\n",
    "        all_patients = np.array(exp.exercises.patients)\n",
    "        \n",
    "        cats = sorted(exp.exercises.categories)\n",
    "        \n",
    "        # init confusion dicts\n",
    "        tp = {}\n",
    "        tn = {}\n",
    "        fp = {}\n",
    "        fn = {}\n",
    "        # iterate over category labels\n",
    "        for cat in cats:\n",
    "            c = int(cat[-1])\n",
    "            exs = exp.exercises.select_category(c)\n",
    "            \n",
    "            # get y values for the patients in the current category\n",
    "            y_cat_valid = y_valid[np.isin(all_patients, np.array(exs.patients))]\n",
    "            y_cat_pred = y_pred[np.isin(all_patients, np.array(exs.patients))]\n",
    "            y_not_cat_valid = y_valid[np.isin(all_patients, np.array(exs.patients), invert=True)]\n",
    "            y_not_cat_pred = y_pred[np.isin(all_patients, np.array(exs.patients), invert=True)]\n",
    "            \n",
    "            tp[c] = y_cat_pred[y_cat_pred == c]\n",
    "            \n",
    "            print(f\"\"\"Category {c}:\n",
    "y_valid in category {c}: {y_cat_valid}\n",
    "y_pred in category {c}: {y_cat_pred}\n",
    "y_valid not in category {c}: {y_not_cat_valid}\n",
    "y_pred not in category {c}: {y_not_cat_pred} \\n\"\"\")\n",
    "            # store confusion per category\n",
    "#             tp[c] = ((y_cat_valid == c) & (y_cat_pred == c))\n",
    "#             tn[c] = ((y_cat_valid != c) & (y_cat_pred != c))\n",
    "#             fp[c] = ((y_cat_valid != c) & (y_cat_pred == c))\n",
    "#             fn[c] = ((y_cat_valid == c) & (y_cat_pred != c))\n",
    "            \n",
    "        return (tp, tn, fp, fn)\n",
    "\n",
    "        \n",
    "def most_common_element(l):\n",
    "    return sorted(l, key=lambda e: l.count(e))[-1]\n",
    "\n",
    "def keep_inliers(self, X, y, c, factor=1.1):\n",
    "    X0 = X[y == c]\n",
    "    mean0 = np.mean(X0)\n",
    "    if np.mean(X[y != c]) < mean0:\n",
    "        min0 = mean0 - factor * max(mean0 - X0)\n",
    "        keep = ((y != c)|(X < min0 ).flatten())\n",
    "    else:\n",
    "        max0 = mean0 + factor * max(X0 - mean0)\n",
    "        keep = ((y != 0)|(X > max0).flatten())\n",
    "    return X[keep], y[keep]\n",
    "\n",
    "def fit_inliers1(exp, feature, factor=1.1, splitter = 'loo', model = None):\n",
    "    _split = model_selectors[splitter]\n",
    "    \n",
    "    fs = FeatureSet(feature)\n",
    "    X = exp.X(fs).to_numpy()\n",
    "    y = np.array(exp.y)\n",
    "    \n",
    "    y_pred = np.zeros(y.shape)\n",
    "    if model is None:\n",
    "        model = LogisticRegression(multi_class='multinomial', \n",
    "                                   solver='sag', \n",
    "                                   penalty='l2', \n",
    "                                   max_iter=10000, \n",
    "                                   warm_start=True)\n",
    "    for train_index, test_index in _split.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        X_train_scaled, X_test_scaled = exp.scale(X_train, X_test)\n",
    "        \n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        \n",
    "        y_pred[test_index] = model.predict(X_test_scaled)\n",
    "    \n",
    "        \n",
    "    return y_pred, model\n",
    "\n",
    "def fit_inliers_ensemble(exp, featureset, factor=1.1, results=None, name=None, splitter = 'loo'):\n",
    "    y_pred = [fit_inliers1(exp, f, factor=factor, splitter=splitter) for f in featureset]\n",
    "    y_pred = [most_common_element(list(y)) for y in zip(*y_pred)]\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import *\n",
    "\n",
    "exs = all_exercises\n",
    "exp = MultivariableExperiment(exs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selectors = {\n",
    "    'loo': LeaveOneOut(),\n",
    "    'kfold': KFold(n_splits=10),\n",
    "    'skfold': StratifiedKFold(n_splits=10),\n",
    "    'rkfold': RepeatedKFold(n_splits=10),\n",
    "    'rskfold': RepeatedStratifiedKFold(n_splits=10),\n",
    "}\n",
    "C_param_range = [0.1,1,10,100]\n",
    "\n",
    "param_combinations = {\n",
    "    'lbfgs': ['l2'],\n",
    "    'sag': ['l2'],\n",
    "    'saga': ['l1', 'l2', 'elasticnet'],\n",
    "    'newton-cg': ['l2']\n",
    "}\n",
    "    \n",
    "ensemble_res = Results.load(f'../Pickle/Def_results_1_234/results_f1.7.pickle')\n",
    "\n",
    "target_names = ['Category 1', 'Category 2', 'Category 3', 'Category 4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: LeaveOneOut\n",
      "solver: lbfgs | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.96      0.85        23\n",
      "  Category 2       0.54      0.66      0.59        32\n",
      "  Category 3       0.53      0.34      0.42        29\n",
      "  Category 4       0.80      0.70      0.74        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.66      0.66      0.65       107\n",
      "weighted avg       0.64      0.64      0.63       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.84      0.91      0.87        23\n",
      "  Category 2       0.55      0.53      0.54        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.80      0.87      0.83        23\n",
      "\n",
      "    accuracy                           0.66       107\n",
      "   macro avg       0.67      0.69      0.68       107\n",
      "weighted avg       0.65      0.66      0.66       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.43      0.41      0.42        32\n",
      "  Category 3       0.46      0.41      0.44        29\n",
      "  Category 4       0.74      0.87      0.80        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.61      0.63      0.62       107\n",
      "weighted avg       0.58      0.60      0.59       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.83      0.79        23\n",
      "  Category 2       0.46      0.41      0.43        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.71      0.87      0.78        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.61      0.64      0.62       107\n",
      "weighted avg       0.59      0.61      0.60       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: sag | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.96      0.85        23\n",
      "  Category 2       0.54      0.66      0.59        32\n",
      "  Category 3       0.53      0.34      0.42        29\n",
      "  Category 4       0.80      0.70      0.74        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.66      0.66      0.65       107\n",
      "weighted avg       0.64      0.64      0.63       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.84      0.91      0.87        23\n",
      "  Category 2       0.55      0.53      0.54        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.80      0.87      0.83        23\n",
      "\n",
      "    accuracy                           0.66       107\n",
      "   macro avg       0.67      0.69      0.68       107\n",
      "weighted avg       0.65      0.66      0.66       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.43      0.41      0.42        32\n",
      "  Category 3       0.44      0.41      0.43        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.60      0.62      0.61       107\n",
      "weighted avg       0.58      0.59      0.58       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.70      0.83      0.76        23\n",
      "  Category 2       0.43      0.38      0.40        32\n",
      "  Category 3       0.44      0.41      0.43        29\n",
      "  Category 4       0.76      0.83      0.79        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.61      0.60       107\n",
      "weighted avg       0.56      0.58      0.57       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: saga | penalty: l1 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.67      0.61      0.64        23\n",
      "  Category 2       0.43      0.69      0.53        32\n",
      "  Category 3       0.29      0.17      0.22        29\n",
      "  Category 4       0.67      0.52      0.59        23\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.51      0.50      0.49       107\n",
      "weighted avg       0.50      0.50      0.48       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.96      0.86        23\n",
      "  Category 2       0.54      0.47      0.50        32\n",
      "  Category 3       0.38      0.34      0.36        29\n",
      "  Category 4       0.72      0.78      0.75        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.61      0.64      0.62       107\n",
      "weighted avg       0.59      0.61      0.59       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.47      0.44      0.45        32\n",
      "  Category 3       0.46      0.41      0.44        29\n",
      "  Category 4       0.74      0.87      0.80        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.62      0.64      0.62       107\n",
      "weighted avg       0.59      0.61      0.60       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.45      0.41      0.43        32\n",
      "  Category 3       0.42      0.38      0.40        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.61      0.59       107\n",
      "weighted avg       0.56      0.58      0.57       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "solver: saga | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.96      0.85        23\n",
      "  Category 2       0.54      0.66      0.59        32\n",
      "  Category 3       0.53      0.34      0.42        29\n",
      "  Category 4       0.80      0.70      0.74        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.66      0.66      0.65       107\n",
      "weighted avg       0.64      0.64      0.63       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.84      0.91      0.87        23\n",
      "  Category 2       0.55      0.53      0.54        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.80      0.87      0.83        23\n",
      "\n",
      "    accuracy                           0.66       107\n",
      "   macro avg       0.67      0.69      0.68       107\n",
      "weighted avg       0.65      0.66      0.66       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.87      0.82        23\n",
      "  Category 2       0.45      0.41      0.43        32\n",
      "  Category 3       0.44      0.41      0.43        29\n",
      "  Category 4       0.76      0.83      0.79        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.61      0.63      0.62       107\n",
      "weighted avg       0.58      0.60      0.59       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.45      0.41      0.43        32\n",
      "  Category 3       0.42      0.38      0.40        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.61      0.59       107\n",
      "weighted avg       0.56      0.58      0.57       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.96      0.85        23\n",
      "  Category 2       0.54      0.66      0.59        32\n",
      "  Category 3       0.53      0.34      0.42        29\n",
      "  Category 4       0.80      0.70      0.74        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.66      0.66      0.65       107\n",
      "weighted avg       0.64      0.64      0.63       107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.96      0.83        23\n",
      "  Category 2       0.54      0.66      0.59        32\n",
      "  Category 3       0.47      0.31      0.38        29\n",
      "  Category 4       0.79      0.65      0.71        23\n",
      "\n",
      "    accuracy                           0.63       107\n",
      "   macro avg       0.63      0.64      0.63       107\n",
      "weighted avg       0.62      0.63      0.61       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.70      0.91      0.79        23\n",
      "  Category 2       0.47      0.53      0.50        32\n",
      "  Category 3       0.36      0.28      0.31        29\n",
      "  Category 4       0.79      0.65      0.71        23\n",
      "\n",
      "    accuracy                           0.57       107\n",
      "   macro avg       0.58      0.59      0.58       107\n",
      "weighted avg       0.56      0.57      0.56       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.74      0.87      0.80        23\n",
      "  Category 2       0.46      0.59      0.52        32\n",
      "  Category 3       0.35      0.28      0.31        29\n",
      "  Category 4       0.81      0.57      0.67        23\n",
      "\n",
      "    accuracy                           0.56       107\n",
      "   macro avg       0.59      0.58      0.57       107\n",
      "weighted avg       0.57      0.56      0.55       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.69      0.78      0.73        23\n",
      "  Category 2       0.48      0.62      0.54        32\n",
      "  Category 3       0.33      0.24      0.28        29\n",
      "  Category 4       0.72      0.57      0.63        23\n",
      "\n",
      "    accuracy                           0.54       107\n",
      "   macro avg       0.56      0.55      0.55       107\n",
      "weighted avg       0.54      0.54      0.53       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.67      0.61      0.64        23\n",
      "  Category 2       0.43      0.69      0.53        32\n",
      "  Category 3       0.29      0.17      0.22        29\n",
      "  Category 4       0.67      0.52      0.59        23\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.51      0.50      0.49       107\n",
      "weighted avg       0.50      0.50      0.48       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.84      0.91      0.87        23\n",
      "  Category 2       0.55      0.53      0.54        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.80      0.87      0.83        23\n",
      "\n",
      "    accuracy                           0.66       107\n",
      "   macro avg       0.67      0.69      0.68       107\n",
      "weighted avg       0.65      0.66      0.66       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.81      0.91      0.86        23\n",
      "  Category 2       0.53      0.53      0.53        32\n",
      "  Category 3       0.42      0.34      0.38        29\n",
      "  Category 4       0.80      0.87      0.83        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.64      0.66      0.65       107\n",
      "weighted avg       0.62      0.64      0.62       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.84      0.91      0.87        23\n",
      "  Category 2       0.53      0.53      0.53        32\n",
      "  Category 3       0.40      0.34      0.37        29\n",
      "  Category 4       0.80      0.87      0.83        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.64      0.66      0.65       107\n",
      "weighted avg       0.62      0.64      0.63       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.81      0.91      0.86        23\n",
      "  Category 2       0.58      0.56      0.57        32\n",
      "  Category 3       0.38      0.34      0.36        29\n",
      "  Category 4       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.63       107\n",
      "   macro avg       0.63      0.65      0.64       107\n",
      "weighted avg       0.61      0.63      0.62       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.96      0.86        23\n",
      "  Category 2       0.56      0.47      0.51        32\n",
      "  Category 3       0.37      0.34      0.36        29\n",
      "  Category 4       0.72      0.78      0.75        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.61      0.64      0.62       107\n",
      "weighted avg       0.59      0.61      0.60       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.96      0.86        23\n",
      "  Category 2       0.54      0.47      0.50        32\n",
      "  Category 3       0.38      0.34      0.36        29\n",
      "  Category 4       0.72      0.78      0.75        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.61      0.64      0.62       107\n",
      "weighted avg       0.59      0.61      0.59       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.87      0.82        23\n",
      "  Category 2       0.45      0.41      0.43        32\n",
      "  Category 3       0.44      0.41      0.43        29\n",
      "  Category 4       0.76      0.83      0.79        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.61      0.63      0.62       107\n",
      "weighted avg       0.58      0.60      0.59       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.80      0.87      0.83        23\n",
      "  Category 2       0.45      0.41      0.43        32\n",
      "  Category 3       0.42      0.38      0.40        29\n",
      "  Category 4       0.70      0.83      0.76        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.59      0.62      0.60       107\n",
      "weighted avg       0.57      0.59      0.58       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.87      0.82        23\n",
      "  Category 2       0.46      0.41      0.43        32\n",
      "  Category 3       0.42      0.38      0.40        29\n",
      "  Category 4       0.70      0.83      0.76        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.59      0.62      0.60       107\n",
      "weighted avg       0.57      0.59      0.58       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.83      0.87      0.85        23\n",
      "  Category 2       0.48      0.44      0.46        32\n",
      "  Category 3       0.44      0.41      0.43        29\n",
      "  Category 4       0.74      0.87      0.80        23\n",
      "\n",
      "    accuracy                           0.62       107\n",
      "   macro avg       0.63      0.65      0.63       107\n",
      "weighted avg       0.60      0.62      0.61       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.83      0.87      0.85        23\n",
      "  Category 2       0.50      0.47      0.48        32\n",
      "  Category 3       0.46      0.41      0.44        29\n",
      "  Category 4       0.74      0.87      0.80        23\n",
      "\n",
      "    accuracy                           0.63       107\n",
      "   macro avg       0.63      0.66      0.64       107\n",
      "weighted avg       0.61      0.63      0.62       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.47      0.44      0.45        32\n",
      "  Category 3       0.46      0.41      0.44        29\n",
      "  Category 4       0.74      0.87      0.80        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.62      0.64      0.62       107\n",
      "weighted avg       0.59      0.61      0.60       107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.45      0.41      0.43        32\n",
      "  Category 3       0.42      0.38      0.40        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.61      0.59       107\n",
      "weighted avg       0.56      0.58      0.57       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.45      0.41      0.43        32\n",
      "  Category 3       0.42      0.38      0.40        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.61      0.59       107\n",
      "weighted avg       0.56      0.58      0.57       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.45      0.41      0.43        32\n",
      "  Category 3       0.42      0.38      0.40        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.61      0.59       107\n",
      "weighted avg       0.56      0.58      0.57       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.45      0.41      0.43        32\n",
      "  Category 3       0.42      0.38      0.40        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.61      0.59       107\n",
      "weighted avg       0.56      0.58      0.57       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.45      0.41      0.43        32\n",
      "  Category 3       0.42      0.38      0.40        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.61      0.59       107\n",
      "weighted avg       0.56      0.58      0.57       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.45      0.41      0.43        32\n",
      "  Category 3       0.42      0.38      0.40        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.61      0.59       107\n",
      "weighted avg       0.56      0.58      0.57       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: newton-cg | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.96      0.85        23\n",
      "  Category 2       0.54      0.66      0.59        32\n",
      "  Category 3       0.53      0.34      0.42        29\n",
      "  Category 4       0.80      0.70      0.74        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.66      0.66      0.65       107\n",
      "weighted avg       0.64      0.64      0.63       107\n",
      "\n",
      "solver: newton-cg | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.84      0.91      0.87        23\n",
      "  Category 2       0.55      0.53      0.54        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.80      0.87      0.83        23\n",
      "\n",
      "    accuracy                           0.66       107\n",
      "   macro avg       0.67      0.69      0.68       107\n",
      "weighted avg       0.65      0.66      0.66       107\n",
      "\n",
      "solver: newton-cg | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.43      0.41      0.42        32\n",
      "  Category 3       0.46      0.41      0.44        29\n",
      "  Category 4       0.74      0.87      0.80        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.61      0.63      0.62       107\n",
      "weighted avg       0.58      0.60      0.59       107\n",
      "\n",
      "solver: newton-cg | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.83      0.79        23\n",
      "  Category 2       0.46      0.41      0.43        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.71      0.87      0.78        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.61      0.64      0.62       107\n",
      "weighted avg       0.59      0.61      0.60       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "CV: KFold\n",
      "solver: lbfgs | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.67      0.70      0.68        23\n",
      "  Category 2       0.38      0.53      0.44        32\n",
      "  Category 3       0.32      0.31      0.32        29\n",
      "  Category 4       0.50      0.22      0.30        23\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.47      0.44      0.44       107\n",
      "weighted avg       0.45      0.44      0.43       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.74      0.76        23\n",
      "  Category 2       0.38      0.50      0.43        32\n",
      "  Category 3       0.38      0.38      0.38        29\n",
      "  Category 4       0.57      0.35      0.43        23\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.53      0.49      0.50       107\n",
      "weighted avg       0.51      0.49      0.49       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.74      0.74      0.74        23\n",
      "  Category 2       0.38      0.44      0.41        32\n",
      "  Category 3       0.38      0.38      0.38        29\n",
      "  Category 4       0.61      0.48      0.54        23\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.53      0.51      0.52       107\n",
      "weighted avg       0.51      0.50      0.50       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.71      0.74      0.72        23\n",
      "  Category 2       0.38      0.41      0.39        32\n",
      "  Category 3       0.41      0.45      0.43        29\n",
      "  Category 4       0.53      0.39      0.45        23\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.51      0.50      0.50       107\n",
      "weighted avg       0.49      0.49      0.49       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: sag | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.67      0.70      0.68        23\n",
      "  Category 2       0.38      0.53      0.44        32\n",
      "  Category 3       0.32      0.31      0.32        29\n",
      "  Category 4       0.50      0.22      0.30        23\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.47      0.44      0.44       107\n",
      "weighted avg       0.45      0.44      0.43       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.74      0.76        23\n",
      "  Category 2       0.38      0.50      0.43        32\n",
      "  Category 3       0.38      0.38      0.38        29\n",
      "  Category 4       0.57      0.35      0.43        23\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.53      0.49      0.50       107\n",
      "weighted avg       0.51      0.49      0.49       107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: sag | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.72      0.78      0.75        23\n",
      "  Category 2       0.42      0.47      0.44        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.63      0.52      0.57        23\n",
      "\n",
      "    accuracy                           0.52       107\n",
      "   macro avg       0.54      0.54      0.54       107\n",
      "weighted avg       0.53      0.52      0.52       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.69      0.78      0.73        23\n",
      "  Category 2       0.40      0.44      0.42        32\n",
      "  Category 3       0.39      0.38      0.39        29\n",
      "  Category 4       0.61      0.48      0.54        23\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.52      0.52      0.52       107\n",
      "weighted avg       0.51      0.50      0.50       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: saga | penalty: l1 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.08      0.04      0.06        23\n",
      "  Category 2       0.00      0.00      0.00        32\n",
      "  Category 3       0.03      0.03      0.03        29\n",
      "  Category 4       0.40      0.17      0.24        23\n",
      "\n",
      "    accuracy                           0.06       107\n",
      "   macro avg       0.13      0.06      0.08       107\n",
      "weighted avg       0.11      0.06      0.07       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.80      0.70      0.74        23\n",
      "  Category 2       0.40      0.53      0.46        32\n",
      "  Category 3       0.34      0.34      0.34        29\n",
      "  Category 4       0.62      0.43      0.51        23\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.54      0.50      0.52       107\n",
      "weighted avg       0.52      0.50      0.50       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.43      0.47      0.45        32\n",
      "  Category 3       0.41      0.41      0.41        29\n",
      "  Category 4       0.68      0.57      0.62        23\n",
      "\n",
      "    accuracy                           0.55       107\n",
      "   macro avg       0.58      0.57      0.57       107\n",
      "weighted avg       0.56      0.55      0.55       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.69      0.78      0.73        23\n",
      "  Category 2       0.42      0.47      0.44        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.61      0.48      0.54        23\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.53      0.53      0.53       107\n",
      "weighted avg       0.52      0.51      0.51       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "solver: saga | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.67      0.70      0.68        23\n",
      "  Category 2       0.38      0.53      0.44        32\n",
      "  Category 3       0.32      0.31      0.32        29\n",
      "  Category 4       0.50      0.22      0.30        23\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.47      0.44      0.44       107\n",
      "weighted avg       0.45      0.44      0.43       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.82      0.78      0.80        23\n",
      "  Category 2       0.41      0.50      0.45        32\n",
      "  Category 3       0.39      0.41      0.40        29\n",
      "  Category 4       0.60      0.39      0.47        23\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.55      0.52      0.53       107\n",
      "weighted avg       0.53      0.51      0.52       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.72      0.78      0.75        23\n",
      "  Category 2       0.42      0.47      0.44        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.63      0.52      0.57        23\n",
      "\n",
      "    accuracy                           0.52       107\n",
      "   macro avg       0.54      0.54      0.54       107\n",
      "weighted avg       0.53      0.52      0.52       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.69      0.78      0.73        23\n",
      "  Category 2       0.42      0.47      0.44        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.61      0.48      0.54        23\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.53      0.53      0.53       107\n",
      "weighted avg       0.52      0.51      0.51       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.67      0.70      0.68        23\n",
      "  Category 2       0.38      0.53      0.44        32\n",
      "  Category 3       0.32      0.31      0.32        29\n",
      "  Category 4       0.50      0.22      0.30        23\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.47      0.44      0.44       107\n",
      "weighted avg       0.45      0.44      0.43       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.62      0.70      0.65        23\n",
      "  Category 2       0.36      0.50      0.42        32\n",
      "  Category 3       0.25      0.24      0.25        29\n",
      "  Category 4       0.44      0.17      0.25        23\n",
      "\n",
      "    accuracy                           0.40       107\n",
      "   macro avg       0.42      0.40      0.39       107\n",
      "weighted avg       0.40      0.40      0.39       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.50      0.39      0.44        23\n",
      "  Category 2       0.24      0.38      0.30        32\n",
      "  Category 3       0.19      0.21      0.20        29\n",
      "  Category 4       0.44      0.17      0.25        23\n",
      "\n",
      "    accuracy                           0.29       107\n",
      "   macro avg       0.35      0.29      0.30       107\n",
      "weighted avg       0.33      0.29      0.29       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.18      0.09      0.12        23\n",
      "  Category 2       0.18      0.31      0.23        32\n",
      "  Category 3       0.09      0.10      0.10        29\n",
      "  Category 4       0.38      0.13      0.19        23\n",
      "\n",
      "    accuracy                           0.17       107\n",
      "   macro avg       0.21      0.16      0.16       107\n",
      "weighted avg       0.20      0.17      0.16       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.08      0.04      0.06        23\n",
      "  Category 2       0.08      0.12      0.10        32\n",
      "  Category 3       0.09      0.10      0.09        29\n",
      "  Category 4       0.44      0.17      0.25        23\n",
      "\n",
      "    accuracy                           0.11       107\n",
      "   macro avg       0.17      0.11      0.12       107\n",
      "weighted avg       0.16      0.11      0.12       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.08      0.04      0.06        23\n",
      "  Category 2       0.00      0.00      0.00        32\n",
      "  Category 3       0.03      0.03      0.03        29\n",
      "  Category 4       0.40      0.17      0.24        23\n",
      "\n",
      "    accuracy                           0.06       107\n",
      "   macro avg       0.13      0.06      0.08       107\n",
      "weighted avg       0.11      0.06      0.07       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.82      0.78      0.80        23\n",
      "  Category 2       0.41      0.50      0.45        32\n",
      "  Category 3       0.39      0.41      0.40        29\n",
      "  Category 4       0.60      0.39      0.47        23\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.55      0.52      0.53       107\n",
      "weighted avg       0.53      0.51      0.52       107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.83      0.83      0.83        23\n",
      "  Category 2       0.42      0.50      0.46        32\n",
      "  Category 3       0.39      0.41      0.40        29\n",
      "  Category 4       0.60      0.39      0.47        23\n",
      "\n",
      "    accuracy                           0.52       107\n",
      "   macro avg       0.56      0.53      0.54       107\n",
      "weighted avg       0.54      0.52      0.52       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.86      0.78      0.82        23\n",
      "  Category 2       0.46      0.56      0.51        32\n",
      "  Category 3       0.39      0.41      0.40        29\n",
      "  Category 4       0.69      0.48      0.56        23\n",
      "\n",
      "    accuracy                           0.55       107\n",
      "   macro avg       0.60      0.56      0.57       107\n",
      "weighted avg       0.57      0.55      0.56       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.85      0.74      0.79        23\n",
      "  Category 2       0.43      0.56      0.49        32\n",
      "  Category 3       0.34      0.34      0.34        29\n",
      "  Category 4       0.69      0.48      0.56        23\n",
      "\n",
      "    accuracy                           0.52       107\n",
      "   macro avg       0.58      0.53      0.55       107\n",
      "weighted avg       0.55      0.52      0.53       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.65      0.71        23\n",
      "  Category 2       0.38      0.50      0.43        32\n",
      "  Category 3       0.32      0.34      0.33        29\n",
      "  Category 4       0.60      0.39      0.47        23\n",
      "\n",
      "    accuracy                           0.47       107\n",
      "   macro avg       0.52      0.47      0.49       107\n",
      "weighted avg       0.50      0.47      0.48       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.70      0.73        23\n",
      "  Category 2       0.39      0.50      0.44        32\n",
      "  Category 3       0.34      0.34      0.34        29\n",
      "  Category 4       0.62      0.43      0.51        23\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.53      0.49      0.51       107\n",
      "weighted avg       0.51      0.49      0.49       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.72      0.78      0.75        23\n",
      "  Category 2       0.42      0.47      0.44        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.63      0.52      0.57        23\n",
      "\n",
      "    accuracy                           0.52       107\n",
      "   macro avg       0.54      0.54      0.54       107\n",
      "weighted avg       0.53      0.52      0.52       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.72      0.78      0.75        23\n",
      "  Category 2       0.42      0.47      0.44        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.63      0.52      0.57        23\n",
      "\n",
      "    accuracy                           0.52       107\n",
      "   macro avg       0.54      0.54      0.54       107\n",
      "weighted avg       0.53      0.52      0.52       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.78      0.77        23\n",
      "  Category 2       0.42      0.47      0.44        32\n",
      "  Category 3       0.39      0.38      0.39        29\n",
      "  Category 4       0.63      0.52      0.57        23\n",
      "\n",
      "    accuracy                           0.52       107\n",
      "   macro avg       0.55      0.54      0.54       107\n",
      "weighted avg       0.53      0.52      0.52       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.83      0.79        23\n",
      "  Category 2       0.43      0.47      0.45        32\n",
      "  Category 3       0.39      0.38      0.39        29\n",
      "  Category 4       0.63      0.52      0.57        23\n",
      "\n",
      "    accuracy                           0.53       107\n",
      "   macro avg       0.55      0.55      0.55       107\n",
      "weighted avg       0.53      0.53      0.53       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.83      0.79        23\n",
      "  Category 2       0.41      0.44      0.42        32\n",
      "  Category 3       0.37      0.38      0.37        29\n",
      "  Category 4       0.67      0.52      0.59        23\n",
      "\n",
      "    accuracy                           0.52       107\n",
      "   macro avg       0.55      0.54      0.54       107\n",
      "weighted avg       0.53      0.52      0.52       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.43      0.47      0.45        32\n",
      "  Category 3       0.41      0.41      0.41        29\n",
      "  Category 4       0.68      0.57      0.62        23\n",
      "\n",
      "    accuracy                           0.55       107\n",
      "   macro avg       0.58      0.57      0.57       107\n",
      "weighted avg       0.56      0.55      0.55       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.69      0.78      0.73        23\n",
      "  Category 2       0.42      0.47      0.44        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.61      0.48      0.54        23\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.53      0.53      0.53       107\n",
      "weighted avg       0.52      0.51      0.51       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.69      0.78      0.73        23\n",
      "  Category 2       0.42      0.47      0.44        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.61      0.48      0.54        23\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.53      0.53      0.53       107\n",
      "weighted avg       0.52      0.51      0.51       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.69      0.78      0.73        23\n",
      "  Category 2       0.42      0.47      0.44        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.61      0.48      0.54        23\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.53      0.53      0.53       107\n",
      "weighted avg       0.52      0.51      0.51       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.69      0.78      0.73        23\n",
      "  Category 2       0.42      0.47      0.44        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.61      0.48      0.54        23\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.53      0.53      0.53       107\n",
      "weighted avg       0.52      0.51      0.51       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.69      0.78      0.73        23\n",
      "  Category 2       0.42      0.47      0.44        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.61      0.48      0.54        23\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.53      0.53      0.53       107\n",
      "weighted avg       0.52      0.51      0.51       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.69      0.78      0.73        23\n",
      "  Category 2       0.42      0.47      0.44        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.61      0.48      0.54        23\n",
      "\n",
      "    accuracy                           0.51       107\n",
      "   macro avg       0.53      0.53      0.53       107\n",
      "weighted avg       0.52      0.51      0.51       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: newton-cg | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.67      0.70      0.68        23\n",
      "  Category 2       0.38      0.53      0.44        32\n",
      "  Category 3       0.32      0.31      0.32        29\n",
      "  Category 4       0.50      0.22      0.30        23\n",
      "\n",
      "    accuracy                           0.44       107\n",
      "   macro avg       0.47      0.44      0.44       107\n",
      "weighted avg       0.45      0.44      0.43       107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: newton-cg | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.74      0.76        23\n",
      "  Category 2       0.38      0.50      0.43        32\n",
      "  Category 3       0.38      0.38      0.38        29\n",
      "  Category 4       0.57      0.35      0.43        23\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.53      0.49      0.50       107\n",
      "weighted avg       0.51      0.49      0.49       107\n",
      "\n",
      "solver: newton-cg | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.74      0.74      0.74        23\n",
      "  Category 2       0.38      0.44      0.41        32\n",
      "  Category 3       0.38      0.38      0.38        29\n",
      "  Category 4       0.61      0.48      0.54        23\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.53      0.51      0.52       107\n",
      "weighted avg       0.51      0.50      0.50       107\n",
      "\n",
      "solver: newton-cg | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.71      0.74      0.72        23\n",
      "  Category 2       0.38      0.41      0.39        32\n",
      "  Category 3       0.41      0.45      0.43        29\n",
      "  Category 4       0.53      0.39      0.45        23\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.51      0.50      0.50       107\n",
      "weighted avg       0.49      0.49      0.49       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "CV: StratifiedKFold\n",
      "solver: lbfgs | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.96      0.85        23\n",
      "  Category 2       0.54      0.62      0.58        32\n",
      "  Category 3       0.50      0.34      0.41        29\n",
      "  Category 4       0.76      0.70      0.73        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.64      0.66      0.64       107\n",
      "weighted avg       0.62      0.64      0.62       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.84      0.91      0.87        23\n",
      "  Category 2       0.50      0.47      0.48        32\n",
      "  Category 3       0.48      0.45      0.46        29\n",
      "  Category 4       0.76      0.83      0.79        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.65      0.66      0.65       107\n",
      "weighted avg       0.62      0.64      0.63       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.83      0.87      0.85        23\n",
      "  Category 2       0.46      0.38      0.41        32\n",
      "  Category 3       0.48      0.48      0.48        29\n",
      "  Category 4       0.71      0.87      0.78        23\n",
      "\n",
      "    accuracy                           0.62       107\n",
      "   macro avg       0.62      0.65      0.63       107\n",
      "weighted avg       0.60      0.62      0.61       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.83      0.87      0.85        23\n",
      "  Category 2       0.44      0.34      0.39        32\n",
      "  Category 3       0.45      0.45      0.45        29\n",
      "  Category 4       0.66      0.83      0.73        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.59      0.62      0.60       107\n",
      "weighted avg       0.57      0.59      0.58       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: sag | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.96      0.83        23\n",
      "  Category 2       0.54      0.62      0.58        32\n",
      "  Category 3       0.53      0.34      0.42        29\n",
      "  Category 4       0.76      0.70      0.73        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.64      0.66      0.64       107\n",
      "weighted avg       0.63      0.64      0.62       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.88      0.91      0.89        23\n",
      "  Category 2       0.50      0.47      0.48        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.76      0.83      0.79        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.65      0.66      0.66       107\n",
      "weighted avg       0.63      0.64      0.63       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.78      0.91      0.84        23\n",
      "  Category 2       0.50      0.41      0.45        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.71      0.87      0.78        23\n",
      "\n",
      "    accuracy                           0.63       107\n",
      "   macro avg       0.62      0.66      0.64       107\n",
      "weighted avg       0.61      0.63      0.61       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.87      0.82        23\n",
      "  Category 2       0.44      0.38      0.41        32\n",
      "  Category 3       0.48      0.45      0.46        29\n",
      "  Category 4       0.70      0.83      0.76        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.60      0.63      0.61       107\n",
      "weighted avg       0.58      0.60      0.59       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: saga | penalty: l1 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.78      0.61      0.68        23\n",
      "  Category 2       0.39      0.69      0.49        32\n",
      "  Category 3       0.38      0.17      0.24        29\n",
      "  Category 4       0.58      0.48      0.52        23\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.53      0.49      0.48       107\n",
      "weighted avg       0.51      0.49      0.47       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.55      0.50      0.52        32\n",
      "  Category 3       0.38      0.34      0.36        29\n",
      "  Category 4       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.61      0.64      0.62       107\n",
      "weighted avg       0.59      0.61      0.60       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.72      0.91      0.81        23\n",
      "  Category 2       0.42      0.31      0.36        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.57      0.61      0.59       107\n",
      "weighted avg       0.55      0.58      0.56       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.44      0.34      0.39        32\n",
      "  Category 3       0.44      0.41      0.43        29\n",
      "  Category 4       0.67      0.78      0.72        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.61      0.59       107\n",
      "weighted avg       0.56      0.58      0.56       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "solver: saga | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.96      0.83        23\n",
      "  Category 2       0.54      0.62      0.58        32\n",
      "  Category 3       0.53      0.34      0.42        29\n",
      "  Category 4       0.76      0.70      0.73        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.64      0.66      0.64       107\n",
      "weighted avg       0.63      0.64      0.62       107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: saga | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.88      0.91      0.89        23\n",
      "  Category 2       0.50      0.47      0.48        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.76      0.83      0.79        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.65      0.66      0.66       107\n",
      "weighted avg       0.63      0.64      0.63       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.50      0.41      0.45        32\n",
      "  Category 3       0.48      0.45      0.46        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.62       107\n",
      "   macro avg       0.62      0.65      0.63       107\n",
      "weighted avg       0.60      0.62      0.60       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.46      0.38      0.41        32\n",
      "  Category 3       0.48      0.45      0.46        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.60      0.63      0.61       107\n",
      "weighted avg       0.58      0.60      0.58       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.96      0.83        23\n",
      "  Category 2       0.54      0.62      0.58        32\n",
      "  Category 3       0.53      0.34      0.42        29\n",
      "  Category 4       0.76      0.70      0.73        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.64      0.66      0.64       107\n",
      "weighted avg       0.63      0.64      0.62       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.96      0.83        23\n",
      "  Category 2       0.50      0.56      0.53        32\n",
      "  Category 3       0.38      0.28      0.32        29\n",
      "  Category 4       0.80      0.70      0.74        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.60      0.62      0.61       107\n",
      "weighted avg       0.58      0.60      0.58       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.72      0.91      0.81        23\n",
      "  Category 2       0.50      0.66      0.57        32\n",
      "  Category 3       0.47      0.31      0.38        29\n",
      "  Category 4       0.82      0.61      0.70        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.63      0.62      0.61       107\n",
      "weighted avg       0.61      0.61      0.60       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.87      0.82        23\n",
      "  Category 2       0.49      0.62      0.55        32\n",
      "  Category 3       0.41      0.31      0.35        29\n",
      "  Category 4       0.72      0.57      0.63        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.60      0.59      0.59       107\n",
      "weighted avg       0.58      0.58      0.57       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.83      0.79        23\n",
      "  Category 2       0.47      0.66      0.55        32\n",
      "  Category 3       0.35      0.21      0.26        29\n",
      "  Category 4       0.60      0.52      0.56        23\n",
      "\n",
      "    accuracy                           0.54       107\n",
      "   macro avg       0.54      0.55      0.54       107\n",
      "weighted avg       0.53      0.54      0.52       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.74      0.61      0.67        23\n",
      "  Category 2       0.39      0.69      0.50        32\n",
      "  Category 3       0.38      0.17      0.24        29\n",
      "  Category 4       0.58      0.48      0.52        23\n",
      "\n",
      "    accuracy                           0.49       107\n",
      "   macro avg       0.52      0.49      0.48       107\n",
      "weighted avg       0.50      0.49      0.47       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.88      0.91      0.89        23\n",
      "  Category 2       0.50      0.47      0.48        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.76      0.83      0.79        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.65      0.66      0.66       107\n",
      "weighted avg       0.63      0.64      0.63       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.88      0.91      0.89        23\n",
      "  Category 2       0.50      0.44      0.47        32\n",
      "  Category 3       0.45      0.45      0.45        29\n",
      "  Category 4       0.77      0.87      0.82        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.65      0.67      0.66       107\n",
      "weighted avg       0.62      0.64      0.63       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.81      0.91      0.86        23\n",
      "  Category 2       0.52      0.47      0.49        32\n",
      "  Category 3       0.43      0.41      0.42        29\n",
      "  Category 4       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.62       107\n",
      "   macro avg       0.63      0.64      0.63       107\n",
      "weighted avg       0.61      0.62      0.61       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.74      0.87      0.80        23\n",
      "  Category 2       0.54      0.47      0.50        32\n",
      "  Category 3       0.43      0.41      0.42        29\n",
      "  Category 4       0.79      0.83      0.81        23\n",
      "\n",
      "    accuracy                           0.62       107\n",
      "   macro avg       0.62      0.64      0.63       107\n",
      "weighted avg       0.61      0.62      0.61       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.74      0.87      0.80        23\n",
      "  Category 2       0.53      0.50      0.52        32\n",
      "  Category 3       0.40      0.34      0.37        29\n",
      "  Category 4       0.76      0.83      0.79        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.61      0.64      0.62       107\n",
      "weighted avg       0.59      0.61      0.60       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.55      0.50      0.52        32\n",
      "  Category 3       0.38      0.34      0.36        29\n",
      "  Category 4       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.61      0.64      0.62       107\n",
      "weighted avg       0.59      0.61      0.60       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.50      0.41      0.45        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.70      0.83      0.76        23\n",
      "\n",
      "    accuracy                           0.62       107\n",
      "   macro avg       0.61      0.65      0.63       107\n",
      "weighted avg       0.60      0.62      0.60       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.46      0.38      0.41        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.72      0.78      0.75        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.60      0.63      0.61       107\n",
      "weighted avg       0.58      0.60      0.59       107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.46      0.38      0.41        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.72      0.78      0.75        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.60      0.63      0.61       107\n",
      "weighted avg       0.58      0.60      0.59       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.78      0.91      0.84        23\n",
      "  Category 2       0.44      0.38      0.41        32\n",
      "  Category 3       0.44      0.41      0.43        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.59      0.62      0.60       107\n",
      "weighted avg       0.57      0.59      0.58       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.44      0.34      0.39        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.59      0.62      0.60       107\n",
      "weighted avg       0.57      0.59      0.57       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.72      0.91      0.81        23\n",
      "  Category 2       0.42      0.31      0.36        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.57      0.61      0.59       107\n",
      "weighted avg       0.55      0.58      0.56       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.46      0.38      0.41        32\n",
      "  Category 3       0.48      0.45      0.46        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.60      0.63      0.61       107\n",
      "weighted avg       0.58      0.60      0.58       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.46      0.38      0.41        32\n",
      "  Category 3       0.46      0.41      0.44        29\n",
      "  Category 4       0.67      0.78      0.72        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.58      0.62      0.60       107\n",
      "weighted avg       0.57      0.59      0.57       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.44      0.34      0.39        32\n",
      "  Category 3       0.44      0.41      0.43        29\n",
      "  Category 4       0.67      0.78      0.72        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.61      0.59       107\n",
      "weighted avg       0.56      0.58      0.56       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.44      0.34      0.39        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.59      0.62      0.60       107\n",
      "weighted avg       0.57      0.59      0.57       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.44      0.34      0.39        32\n",
      "  Category 3       0.44      0.41      0.43        29\n",
      "  Category 4       0.67      0.78      0.72        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.61      0.59       107\n",
      "weighted avg       0.56      0.58      0.56       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.44      0.34      0.39        32\n",
      "  Category 3       0.44      0.41      0.43        29\n",
      "  Category 4       0.67      0.78      0.72        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.61      0.59       107\n",
      "weighted avg       0.56      0.58      0.56       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: newton-cg | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.96      0.85        23\n",
      "  Category 2       0.54      0.62      0.58        32\n",
      "  Category 3       0.50      0.34      0.41        29\n",
      "  Category 4       0.76      0.70      0.73        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.64      0.66      0.64       107\n",
      "weighted avg       0.62      0.64      0.62       107\n",
      "\n",
      "solver: newton-cg | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.84      0.91      0.87        23\n",
      "  Category 2       0.50      0.47      0.48        32\n",
      "  Category 3       0.48      0.45      0.46        29\n",
      "  Category 4       0.76      0.83      0.79        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.65      0.66      0.65       107\n",
      "weighted avg       0.62      0.64      0.63       107\n",
      "\n",
      "solver: newton-cg | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.83      0.87      0.85        23\n",
      "  Category 2       0.46      0.38      0.41        32\n",
      "  Category 3       0.48      0.48      0.48        29\n",
      "  Category 4       0.71      0.87      0.78        23\n",
      "\n",
      "    accuracy                           0.62       107\n",
      "   macro avg       0.62      0.65      0.63       107\n",
      "weighted avg       0.60      0.62      0.61       107\n",
      "\n",
      "solver: newton-cg | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.83      0.87      0.85        23\n",
      "  Category 2       0.44      0.34      0.39        32\n",
      "  Category 3       0.45      0.45      0.45        29\n",
      "  Category 4       0.66      0.83      0.73        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.59      0.62      0.60       107\n",
      "weighted avg       0.57      0.59      0.58       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "CV: RepeatedKFold\n",
      "solver: lbfgs | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.96      0.85        23\n",
      "  Category 2       0.63      0.69      0.66        32\n",
      "  Category 3       0.58      0.48      0.53        29\n",
      "  Category 4       0.89      0.74      0.81        23\n",
      "\n",
      "    accuracy                           0.70       107\n",
      "   macro avg       0.72      0.72      0.71       107\n",
      "weighted avg       0.70      0.70      0.70       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.83      0.87      0.85        23\n",
      "  Category 2       0.53      0.53      0.53        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.78      0.78      0.78        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.65      0.66      0.66       107\n",
      "weighted avg       0.63      0.64      0.63       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.83      0.79        23\n",
      "  Category 2       0.54      0.47      0.50        32\n",
      "  Category 3       0.43      0.45      0.44        29\n",
      "  Category 4       0.71      0.74      0.72        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.61      0.62      0.61       107\n",
      "weighted avg       0.59      0.60      0.59       107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: lbfgs | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.80      0.87      0.83        23\n",
      "  Category 2       0.50      0.44      0.47        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.65      0.74      0.69        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.60      0.62      0.61       107\n",
      "weighted avg       0.59      0.60      0.59       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: sag | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.56      0.62      0.59        32\n",
      "  Category 3       0.54      0.45      0.49        29\n",
      "  Category 4       0.84      0.70      0.76        23\n",
      "\n",
      "    accuracy                           0.65       107\n",
      "   macro avg       0.67      0.67      0.67       107\n",
      "weighted avg       0.66      0.65      0.65       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.83      0.87      0.85        23\n",
      "  Category 2       0.52      0.50      0.51        32\n",
      "  Category 3       0.47      0.48      0.47        29\n",
      "  Category 4       0.86      0.83      0.84        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.67      0.67      0.67       107\n",
      "weighted avg       0.65      0.64      0.64       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.91      0.87      0.89        23\n",
      "  Category 2       0.54      0.47      0.50        32\n",
      "  Category 3       0.44      0.48      0.46        29\n",
      "  Category 4       0.68      0.74      0.71        23\n",
      "\n",
      "    accuracy                           0.62       107\n",
      "   macro avg       0.64      0.64      0.64       107\n",
      "weighted avg       0.62      0.62      0.62       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.48      0.44      0.46        32\n",
      "  Category 3       0.48      0.45      0.46        29\n",
      "  Category 4       0.70      0.83      0.76        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.61      0.63      0.62       107\n",
      "weighted avg       0.60      0.61      0.60       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: saga | penalty: l1 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.57      0.57      0.57        23\n",
      "  Category 2       0.38      0.62      0.48        32\n",
      "  Category 3       0.31      0.14      0.19        29\n",
      "  Category 4       0.68      0.57      0.62        23\n",
      "\n",
      "    accuracy                           0.47       107\n",
      "   macro avg       0.49      0.47      0.46       107\n",
      "weighted avg       0.47      0.47      0.45       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.81      0.91      0.86        23\n",
      "  Category 2       0.50      0.47      0.48        32\n",
      "  Category 3       0.32      0.31      0.32        29\n",
      "  Category 4       0.74      0.74      0.74        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.59      0.61      0.60       107\n",
      "weighted avg       0.57      0.58      0.57       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.74      0.87      0.80        23\n",
      "  Category 2       0.58      0.47      0.52        32\n",
      "  Category 3       0.53      0.55      0.54        29\n",
      "  Category 4       0.71      0.74      0.72        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.64      0.66      0.65       107\n",
      "weighted avg       0.63      0.64      0.63       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.72      0.91      0.81        23\n",
      "  Category 2       0.50      0.47      0.48        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.75      0.65      0.70        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.61      0.62      0.61       107\n",
      "weighted avg       0.59      0.60      0.59       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "solver: saga | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.71      0.96      0.81        23\n",
      "  Category 2       0.61      0.62      0.62        32\n",
      "  Category 3       0.62      0.52      0.57        29\n",
      "  Category 4       0.79      0.65      0.71        23\n",
      "\n",
      "    accuracy                           0.67       107\n",
      "   macro avg       0.68      0.69      0.68       107\n",
      "weighted avg       0.67      0.67      0.67       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.84      0.91      0.87        23\n",
      "  Category 2       0.55      0.50      0.52        32\n",
      "  Category 3       0.50      0.48      0.49        29\n",
      "  Category 4       0.72      0.78      0.75        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.65      0.67      0.66       107\n",
      "weighted avg       0.64      0.64      0.64       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.41      0.44      0.42        32\n",
      "  Category 3       0.43      0.31      0.36        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.56       107\n",
      "   macro avg       0.57      0.59      0.57       107\n",
      "weighted avg       0.55      0.56      0.55       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.80      0.87      0.83        23\n",
      "  Category 2       0.40      0.31      0.35        32\n",
      "  Category 3       0.40      0.41      0.41        29\n",
      "  Category 4       0.70      0.83      0.76        23\n",
      "\n",
      "    accuracy                           0.57       107\n",
      "   macro avg       0.58      0.61      0.59       107\n",
      "weighted avg       0.55      0.57      0.56       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.96      0.86        23\n",
      "  Category 2       0.53      0.66      0.58        32\n",
      "  Category 3       0.53      0.34      0.42        29\n",
      "  Category 4       0.75      0.65      0.70        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.65      0.65      0.64       107\n",
      "weighted avg       0.63      0.64      0.62       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.96      0.83        23\n",
      "  Category 2       0.54      0.66      0.59        32\n",
      "  Category 3       0.45      0.31      0.37        29\n",
      "  Category 4       0.89      0.70      0.78        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.65      0.65      0.64       107\n",
      "weighted avg       0.63      0.64      0.62       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.70      0.91      0.79        23\n",
      "  Category 2       0.49      0.59      0.54        32\n",
      "  Category 3       0.43      0.34      0.38        29\n",
      "  Category 4       0.87      0.57      0.68        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.62      0.60      0.60       107\n",
      "weighted avg       0.60      0.59      0.58       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.70      0.91      0.79        23\n",
      "  Category 2       0.46      0.56      0.51        32\n",
      "  Category 3       0.45      0.31      0.37        29\n",
      "  Category 4       0.83      0.65      0.73        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.61      0.61      0.60       107\n",
      "weighted avg       0.59      0.59      0.58       107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.64      0.61      0.62        23\n",
      "  Category 2       0.41      0.59      0.49        32\n",
      "  Category 3       0.30      0.24      0.27        29\n",
      "  Category 4       0.81      0.57      0.67        23\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.54      0.50      0.51       107\n",
      "weighted avg       0.52      0.50      0.50       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.68      0.65      0.67        23\n",
      "  Category 2       0.42      0.69      0.52        32\n",
      "  Category 3       0.27      0.14      0.18        29\n",
      "  Category 4       0.72      0.57      0.63        23\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.52      0.51      0.50       107\n",
      "weighted avg       0.50      0.50      0.49       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.87      0.87      0.87        23\n",
      "  Category 2       0.47      0.44      0.45        32\n",
      "  Category 3       0.39      0.38      0.39        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.61      0.63      0.62       107\n",
      "weighted avg       0.59      0.60      0.59       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.88      0.91      0.89        23\n",
      "  Category 2       0.57      0.50      0.53        32\n",
      "  Category 3       0.52      0.52      0.52        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.66       107\n",
      "   macro avg       0.67      0.69      0.68       107\n",
      "weighted avg       0.66      0.66      0.66       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.88      0.96      0.92        23\n",
      "  Category 2       0.61      0.59      0.60        32\n",
      "  Category 3       0.44      0.41      0.43        29\n",
      "  Category 4       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.66       107\n",
      "   macro avg       0.67      0.69      0.68       107\n",
      "weighted avg       0.65      0.66      0.66       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.71      0.96      0.81        23\n",
      "  Category 2       0.52      0.44      0.47        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.77      0.74      0.76        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.60      0.63      0.61       107\n",
      "weighted avg       0.58      0.60      0.59       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.88      0.91      0.89        23\n",
      "  Category 2       0.49      0.53      0.51        32\n",
      "  Category 3       0.33      0.28      0.30        29\n",
      "  Category 4       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.61      0.63      0.62       107\n",
      "weighted avg       0.58      0.60      0.59       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.78      0.91      0.84        23\n",
      "  Category 2       0.54      0.47      0.50        32\n",
      "  Category 3       0.39      0.38      0.39        29\n",
      "  Category 4       0.71      0.74      0.72        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.60      0.63      0.61       107\n",
      "weighted avg       0.59      0.60      0.59       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.68      0.91      0.78        23\n",
      "  Category 2       0.52      0.41      0.46        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.68      0.74      0.71        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.59      0.63      0.60       107\n",
      "weighted avg       0.58      0.60      0.58       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.50      0.50      0.50        32\n",
      "  Category 3       0.45      0.45      0.45        29\n",
      "  Category 4       0.77      0.74      0.76        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.63      0.63      0.63       107\n",
      "weighted avg       0.61      0.61      0.61       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.48      0.41      0.44        32\n",
      "  Category 3       0.54      0.48      0.51        29\n",
      "  Category 4       0.67      0.87      0.75        23\n",
      "\n",
      "    accuracy                           0.62       107\n",
      "   macro avg       0.62      0.65      0.63       107\n",
      "weighted avg       0.60      0.62      0.61       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.83      0.83      0.83        23\n",
      "  Category 2       0.52      0.47      0.49        32\n",
      "  Category 3       0.42      0.45      0.43        29\n",
      "  Category 4       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.63      0.63      0.63       107\n",
      "weighted avg       0.61      0.61      0.61       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.84      0.91      0.87        23\n",
      "  Category 2       0.59      0.50      0.54        32\n",
      "  Category 3       0.53      0.55      0.54        29\n",
      "  Category 4       0.72      0.78      0.75        23\n",
      "\n",
      "    accuracy                           0.66       107\n",
      "   macro avg       0.67      0.69      0.68       107\n",
      "weighted avg       0.66      0.66      0.66       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.80      0.87      0.83        23\n",
      "  Category 2       0.48      0.38      0.42        32\n",
      "  Category 3       0.50      0.55      0.52        29\n",
      "  Category 4       0.72      0.78      0.75        23\n",
      "\n",
      "    accuracy                           0.62       107\n",
      "   macro avg       0.62      0.64      0.63       107\n",
      "weighted avg       0.61      0.62      0.61       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.72      0.78      0.75        23\n",
      "  Category 2       0.32      0.28      0.30        32\n",
      "  Category 3       0.40      0.41      0.41        29\n",
      "  Category 4       0.71      0.74      0.72        23\n",
      "\n",
      "    accuracy                           0.52       107\n",
      "   macro avg       0.54      0.55      0.55       107\n",
      "weighted avg       0.51      0.52      0.52       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.87      0.82        23\n",
      "  Category 2       0.41      0.34      0.37        32\n",
      "  Category 3       0.45      0.48      0.47        29\n",
      "  Category 4       0.74      0.74      0.74        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.59      0.61      0.60       107\n",
      "weighted avg       0.57      0.58      0.57       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.83      0.79        23\n",
      "  Category 2       0.46      0.41      0.43        32\n",
      "  Category 3       0.42      0.38      0.40        29\n",
      "  Category 4       0.71      0.87      0.78        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.59      0.62      0.60       107\n",
      "weighted avg       0.57      0.59      0.58       107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.83      0.79        23\n",
      "  Category 2       0.50      0.47      0.48        32\n",
      "  Category 3       0.46      0.41      0.44        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.60      0.62      0.61       107\n",
      "weighted avg       0.59      0.60      0.59       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.52      0.53      0.52        32\n",
      "  Category 3       0.43      0.34      0.38        29\n",
      "  Category 4       0.64      0.70      0.67        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.60      0.59       107\n",
      "weighted avg       0.57      0.58      0.57       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.52      0.50      0.51        32\n",
      "  Category 3       0.52      0.48      0.50        29\n",
      "  Category 4       0.72      0.78      0.75        23\n",
      "\n",
      "    accuracy                           0.63       107\n",
      "   macro avg       0.64      0.65      0.64       107\n",
      "weighted avg       0.62      0.63      0.62       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: newton-cg | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.54      0.59      0.57        32\n",
      "  Category 3       0.54      0.45      0.49        29\n",
      "  Category 4       0.80      0.70      0.74        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.66      0.66      0.66       107\n",
      "weighted avg       0.64      0.64      0.64       107\n",
      "\n",
      "solver: newton-cg | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.87      0.82        23\n",
      "  Category 2       0.45      0.41      0.43        32\n",
      "  Category 3       0.41      0.38      0.39        29\n",
      "  Category 4       0.80      0.87      0.83        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.61      0.63      0.62       107\n",
      "weighted avg       0.58      0.60      0.59       107\n",
      "\n",
      "solver: newton-cg | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.41      0.38      0.39        32\n",
      "  Category 3       0.45      0.48      0.47        29\n",
      "  Category 4       0.83      0.83      0.83        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.62      0.63      0.62       107\n",
      "weighted avg       0.59      0.60      0.60       107\n",
      "\n",
      "solver: newton-cg | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.48      0.47      0.48        32\n",
      "  Category 3       0.46      0.41      0.44        29\n",
      "  Category 4       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.61      0.62      0.61       107\n",
      "weighted avg       0.59      0.60      0.59       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "CV: RepeatedStratifiedKFold\n",
      "solver: lbfgs | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.56      0.59      0.58        32\n",
      "  Category 3       0.54      0.45      0.49        29\n",
      "  Category 4       0.76      0.70      0.73        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.65      0.66      0.65       107\n",
      "weighted avg       0.64      0.64      0.64       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.81      0.91      0.86        23\n",
      "  Category 2       0.57      0.53      0.55        32\n",
      "  Category 3       0.48      0.41      0.44        29\n",
      "  Category 4       0.77      0.87      0.82        23\n",
      "\n",
      "    accuracy                           0.65       107\n",
      "   macro avg       0.66      0.68      0.67       107\n",
      "weighted avg       0.64      0.65      0.64       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.74      0.87      0.80        23\n",
      "  Category 2       0.57      0.50      0.53        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.64      0.66      0.65       107\n",
      "weighted avg       0.62      0.64      0.63       107\n",
      "\n",
      "solver: lbfgs | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.46      0.41      0.43        32\n",
      "  Category 3       0.48      0.45      0.46        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.59      0.62      0.60       107\n",
      "weighted avg       0.58      0.59      0.58       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: sag | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.71      0.96      0.81        23\n",
      "  Category 2       0.58      0.66      0.62        32\n",
      "  Category 3       0.53      0.34      0.42        29\n",
      "  Category 4       0.76      0.70      0.73        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.65      0.66      0.64       107\n",
      "weighted avg       0.63      0.64      0.63       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.80      0.87      0.83        23\n",
      "  Category 2       0.59      0.53      0.56        32\n",
      "  Category 3       0.48      0.45      0.46        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.64      0.66      0.65       107\n",
      "weighted avg       0.63      0.64      0.63       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.91      0.82        23\n",
      "  Category 2       0.52      0.44      0.47        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.77      0.87      0.82        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.63      0.67      0.65       107\n",
      "weighted avg       0.62      0.64      0.62       107\n",
      "\n",
      "solver: sag | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.74      0.87      0.80        23\n",
      "  Category 2       0.43      0.41      0.42        32\n",
      "  Category 3       0.38      0.31      0.34        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.57       107\n",
      "   macro avg       0.57      0.60      0.58       107\n",
      "weighted avg       0.55      0.57      0.56       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: saga | penalty: l1 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.64      0.70      0.67        23\n",
      "  Category 2       0.49      0.66      0.56        32\n",
      "  Category 3       0.45      0.31      0.37        29\n",
      "  Category 4       0.68      0.57      0.62        23\n",
      "\n",
      "    accuracy                           0.55       107\n",
      "   macro avg       0.57      0.56      0.55       107\n",
      "weighted avg       0.55      0.55      0.54       107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: saga | penalty: l1 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.69      0.87      0.77        23\n",
      "  Category 2       0.57      0.50      0.53        32\n",
      "  Category 3       0.46      0.38      0.42        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.60      0.63      0.61       107\n",
      "weighted avg       0.59      0.61      0.60       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.80      0.87      0.83        23\n",
      "  Category 2       0.48      0.44      0.46        32\n",
      "  Category 3       0.48      0.45      0.46        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.62       107\n",
      "   macro avg       0.62      0.65      0.63       107\n",
      "weighted avg       0.60      0.62      0.61       107\n",
      "\n",
      "solver: saga | penalty: l1 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.87      0.82        23\n",
      "  Category 2       0.50      0.41      0.45        32\n",
      "  Category 3       0.45      0.45      0.45        29\n",
      "  Category 4       0.77      0.87      0.82        23\n",
      "\n",
      "    accuracy                           0.62       107\n",
      "   macro avg       0.62      0.65      0.63       107\n",
      "weighted avg       0.60      0.62      0.61       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "solver: saga | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.71      0.96      0.81        23\n",
      "  Category 2       0.51      0.56      0.54        32\n",
      "  Category 3       0.55      0.38      0.45        29\n",
      "  Category 4       0.76      0.70      0.73        23\n",
      "\n",
      "    accuracy                           0.63       107\n",
      "   macro avg       0.63      0.65      0.63       107\n",
      "weighted avg       0.62      0.63      0.61       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.78      0.91      0.84        23\n",
      "  Category 2       0.46      0.38      0.41        32\n",
      "  Category 3       0.43      0.45      0.44        29\n",
      "  Category 4       0.79      0.83      0.81        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.62      0.64      0.63       107\n",
      "weighted avg       0.59      0.61      0.60       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.83      0.79        23\n",
      "  Category 2       0.45      0.41      0.43        32\n",
      "  Category 3       0.48      0.48      0.48        29\n",
      "  Category 4       0.71      0.74      0.72        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.60      0.61      0.61       107\n",
      "weighted avg       0.58      0.59      0.58       107\n",
      "\n",
      "solver: saga | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.74      0.87      0.80        23\n",
      "  Category 2       0.45      0.44      0.44        32\n",
      "  Category 3       0.42      0.34      0.38        29\n",
      "  Category 4       0.68      0.74      0.71        23\n",
      "\n",
      "    accuracy                           0.57       107\n",
      "   macro avg       0.57      0.60      0.58       107\n",
      "weighted avg       0.55      0.57      0.56       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.96      0.83        23\n",
      "  Category 2       0.58      0.59      0.58        32\n",
      "  Category 3       0.52      0.38      0.44        29\n",
      "  Category 4       0.78      0.78      0.78        23\n",
      "\n",
      "    accuracy                           0.65       107\n",
      "   macro avg       0.65      0.68      0.66       107\n",
      "weighted avg       0.64      0.65      0.64       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.71      0.96      0.81        23\n",
      "  Category 2       0.54      0.69      0.60        32\n",
      "  Category 3       0.56      0.34      0.43        29\n",
      "  Category 4       0.88      0.65      0.75        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.67      0.66      0.65       107\n",
      "weighted avg       0.65      0.64      0.63       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.96      0.83        23\n",
      "  Category 2       0.56      0.59      0.58        32\n",
      "  Category 3       0.46      0.41      0.44        29\n",
      "  Category 4       0.88      0.65      0.75        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.66      0.65      0.65       107\n",
      "weighted avg       0.64      0.64      0.63       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.74      0.87      0.80        23\n",
      "  Category 2       0.49      0.62      0.55        32\n",
      "  Category 3       0.32      0.21      0.25        29\n",
      "  Category 4       0.75      0.65      0.70        23\n",
      "\n",
      "    accuracy                           0.57       107\n",
      "   macro avg       0.57      0.59      0.57       107\n",
      "weighted avg       0.55      0.57      0.55       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.75      0.78      0.77        23\n",
      "  Category 2       0.51      0.75      0.61        32\n",
      "  Category 3       0.42      0.28      0.33        29\n",
      "  Category 4       0.76      0.57      0.65        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.61      0.59      0.59       107\n",
      "weighted avg       0.59      0.59      0.58       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 0.1 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.74      0.61      0.67        23\n",
      "  Category 2       0.43      0.72      0.54        32\n",
      "  Category 3       0.31      0.17      0.22        29\n",
      "  Category 4       0.63      0.52      0.57        23\n",
      "\n",
      "    accuracy                           0.50       107\n",
      "   macro avg       0.53      0.51      0.50       107\n",
      "weighted avg       0.51      0.50      0.49       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.78      0.91      0.84        23\n",
      "  Category 2       0.52      0.47      0.49        32\n",
      "  Category 3       0.48      0.41      0.44        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.63       107\n",
      "   macro avg       0.63      0.66      0.64       107\n",
      "weighted avg       0.61      0.63      0.61       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.87      0.82        23\n",
      "  Category 2       0.50      0.50      0.50        32\n",
      "  Category 3       0.44      0.38      0.41        29\n",
      "  Category 4       0.71      0.74      0.72        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.60      0.62      0.61       107\n",
      "weighted avg       0.59      0.60      0.59       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.81      0.91      0.86        23\n",
      "  Category 2       0.53      0.59      0.56        32\n",
      "  Category 3       0.36      0.31      0.33        29\n",
      "  Category 4       0.75      0.65      0.70        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.61      0.62      0.61       107\n",
      "weighted avg       0.59      0.60      0.59       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.81      0.96      0.88        23\n",
      "  Category 2       0.52      0.50      0.51        32\n",
      "  Category 3       0.43      0.34      0.38        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.63       107\n",
      "   macro avg       0.62      0.66      0.64       107\n",
      "weighted avg       0.60      0.63      0.61       107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.96      0.86        23\n",
      "  Category 2       0.55      0.50      0.52        32\n",
      "  Category 3       0.42      0.38      0.40        29\n",
      "  Category 4       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.63       107\n",
      "   macro avg       0.63      0.65      0.64       107\n",
      "weighted avg       0.61      0.63      0.62       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 1 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.78      0.91      0.84        23\n",
      "  Category 2       0.52      0.50      0.51        32\n",
      "  Category 3       0.42      0.38      0.40        29\n",
      "  Category 4       0.74      0.74      0.74        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.61      0.63      0.62       107\n",
      "weighted avg       0.60      0.61      0.60       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.87      0.82        23\n",
      "  Category 2       0.54      0.47      0.50        32\n",
      "  Category 3       0.54      0.48      0.51        29\n",
      "  Category 4       0.70      0.83      0.76        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.64      0.66      0.65       107\n",
      "weighted avg       0.62      0.64      0.63       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.45      0.44      0.44        32\n",
      "  Category 3       0.42      0.34      0.38        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.57       107\n",
      "   macro avg       0.57      0.60      0.58       107\n",
      "weighted avg       0.55      0.57      0.56       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.83      0.83      0.83        23\n",
      "  Category 2       0.59      0.59      0.59        32\n",
      "  Category 3       0.54      0.48      0.51        29\n",
      "  Category 4       0.77      0.87      0.82        23\n",
      "\n",
      "    accuracy                           0.67       107\n",
      "   macro avg       0.68      0.69      0.69       107\n",
      "weighted avg       0.67      0.67      0.67       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.83      0.83      0.83        23\n",
      "  Category 2       0.47      0.47      0.47        32\n",
      "  Category 3       0.38      0.34      0.36        29\n",
      "  Category 4       0.73      0.83      0.78        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.60      0.62      0.61       107\n",
      "weighted avg       0.58      0.59      0.58       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.72      0.78      0.75        23\n",
      "  Category 2       0.48      0.41      0.44        32\n",
      "  Category 3       0.50      0.48      0.49        29\n",
      "  Category 4       0.63      0.74      0.68        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.58      0.60      0.59       107\n",
      "weighted avg       0.57      0.58      0.57       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 10 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.78      0.78      0.78        23\n",
      "  Category 2       0.52      0.47      0.49        32\n",
      "  Category 3       0.39      0.45      0.42        29\n",
      "  Category 4       0.73      0.70      0.71        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.61      0.60      0.60       107\n",
      "weighted avg       0.59      0.58      0.58       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.77      0.87      0.82        23\n",
      "  Category 2       0.55      0.50      0.52        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.69      0.78      0.73        23\n",
      "\n",
      "    accuracy                           0.63       107\n",
      "   macro avg       0.63      0.65      0.64       107\n",
      "weighted avg       0.61      0.63      0.62       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.83      0.79        23\n",
      "  Category 2       0.47      0.44      0.45        32\n",
      "  Category 3       0.41      0.41      0.41        29\n",
      "  Category 4       0.74      0.74      0.74        23\n",
      "\n",
      "    accuracy                           0.58       107\n",
      "   macro avg       0.59      0.60      0.60       107\n",
      "weighted avg       0.57      0.58      0.58       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.76      0.83      0.79        23\n",
      "  Category 2       0.47      0.44      0.45        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.71      0.74      0.72        23\n",
      "\n",
      "    accuracy                           0.59       107\n",
      "   macro avg       0.60      0.61      0.61       107\n",
      "weighted avg       0.58      0.59      0.58       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.42      0.41      0.41        32\n",
      "  Category 3       0.40      0.34      0.37        29\n",
      "  Category 4       0.70      0.83      0.76        23\n",
      "\n",
      "    accuracy                           0.57       107\n",
      "   macro avg       0.58      0.60      0.59       107\n",
      "weighted avg       0.56      0.57      0.56       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 0.8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.71      0.87      0.78        23\n",
      "  Category 2       0.50      0.41      0.45        32\n",
      "  Category 3       0.47      0.48      0.47        29\n",
      "  Category 4       0.74      0.74      0.74        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.61      0.62      0.61       107\n",
      "weighted avg       0.59      0.60      0.59       107\n",
      "\n",
      "solver: saga | penalty: elasticnet | C: 100 | l1_ratio: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.66      0.83      0.73        23\n",
      "  Category 2       0.50      0.44      0.47        32\n",
      "  Category 3       0.50      0.45      0.47        29\n",
      "  Category 4       0.75      0.78      0.77        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.60      0.62      0.61       107\n",
      "weighted avg       0.59      0.60      0.59       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n",
      "solver: newton-cg | penalty: l2 | C: 0.1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.96      0.86        23\n",
      "  Category 2       0.54      0.62      0.58        32\n",
      "  Category 3       0.55      0.38      0.45        29\n",
      "  Category 4       0.73      0.70      0.71        23\n",
      "\n",
      "    accuracy                           0.64       107\n",
      "   macro avg       0.65      0.66      0.65       107\n",
      "weighted avg       0.64      0.64      0.63       107\n",
      "\n",
      "solver: newton-cg | penalty: l2 | C: 1 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.83      0.87      0.85        23\n",
      "  Category 2       0.58      0.56      0.57        32\n",
      "  Category 3       0.46      0.45      0.46        29\n",
      "  Category 4       0.79      0.83      0.81        23\n",
      "\n",
      "    accuracy                           0.65       107\n",
      "   macro avg       0.67      0.68      0.67       107\n",
      "weighted avg       0.65      0.65      0.65       107\n",
      "\n",
      "solver: newton-cg | penalty: l2 | C: 10 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.79      0.83      0.81        23\n",
      "  Category 2       0.50      0.41      0.45        32\n",
      "  Category 3       0.42      0.48      0.45        29\n",
      "  Category 4       0.79      0.83      0.81        23\n",
      "\n",
      "    accuracy                           0.61       107\n",
      "   macro avg       0.63      0.64      0.63       107\n",
      "weighted avg       0.60      0.61      0.60       107\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: newton-cg | penalty: l2 | C: 100 | l1_ratio: None\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "  Category 1       0.73      0.83      0.78        23\n",
      "  Category 2       0.50      0.44      0.47        32\n",
      "  Category 3       0.52      0.48      0.50        29\n",
      "  Category 4       0.65      0.74      0.69        23\n",
      "\n",
      "    accuracy                           0.60       107\n",
      "   macro avg       0.60      0.62      0.61       107\n",
      "weighted avg       0.59      0.60      0.59       107\n",
      "\n",
      "-------------------------------------- CHANGING PENALTY\n",
      "-------------------------------------- CHANGING SOLVER\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results = {}\n",
    "for splitter, obj in model_selectors.items():\n",
    "    print(f'CV: {type(obj).__name__}')\n",
    "    results[type(obj).__name__] = []\n",
    "    for solver, penalties in param_combinations.items():\n",
    "        for pen in penalties:\n",
    "            for C in C_param_range:\n",
    "                args = dict(\n",
    "                    multi_class='multinomial', \n",
    "                    solver=solver, \n",
    "                    penalty=pen, \n",
    "                    max_iter=10000, \n",
    "                    C=C\n",
    "                )\n",
    "                if pen == 'elasticnet':\n",
    "                    l1_ratio = [0, 0.2, 0.4, 0.6, 0.8, 1.0]\n",
    "                else:\n",
    "                    l1_ratio = [None]\n",
    "                for r in l1_ratio:\n",
    "                    args['l1_ratio'] = r\n",
    "                    model = LogisticRegression(**args)\n",
    "                    try:\n",
    "                        y_pred, model = fit_inliers1(exp, exp.cols, factor=1.1, splitter=splitter, model=model)\n",
    "                    except Exception as e:\n",
    "                        print(f'fitting with params (solver: {solver} | penalty: {pen} | C: {C}) FAILED\\n',e)\n",
    "                        continue\n",
    "\n",
    "                    res = MultivariableResults(exp)\n",
    "\n",
    "                    report = classification_report(exp.y, y_pred, \n",
    "                                                                output_dict=False, \n",
    "                                                                target_names=target_names\n",
    "                                                               )\n",
    "                    report_dict = classification_report(exp.y, y_pred, \n",
    "                                                                output_dict=True, \n",
    "                                                                target_names=target_names\n",
    "                                                               )\n",
    "                    results[type(obj).__name__].append({\n",
    "                        'penalty': pen,\n",
    "                        'C': C,\n",
    "                        'report': report_dict,\n",
    "                        'model': model,\n",
    "                        'l1_ratio': r\n",
    "                    })\n",
    "                    print(f\"\"\"solver: {solver} | penalty: {pen} | C: {C} | l1_ratio: {r}\n",
    "{report}\"\"\")\n",
    "            print('-------------------------------------- CHANGING PENALTY')\n",
    "                \n",
    "        print('-------------------------------------- CHANGING SOLVER')\n",
    "#     res.score(exp.cols, exp.y, y_pred)\n",
    "#     print(type(obj), '\\n', res.report())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "file = 'dumps/results_dump_mlp_14_12.pickle'\n",
    "with open(file, 'wb') as fout:\n",
    "    pickle.dump(results, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'LeaveOneOut': [{'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7586206896551724,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8461538461538461,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5384615384615384,\n",
       "     'recall': 0.65625,\n",
       "     'f1-score': 0.5915492957746479,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5263157894736842,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.4166666666666667,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7441860465116279,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6448598130841121,\n",
       "    'macro avg': {'precision': 0.6558495043975987,\n",
       "     'recall': 0.6633128748125937,\n",
       "     'f1-score': 0.6496389637766972,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6387121774539722,\n",
       "     'recall': 0.6448598130841121,\n",
       "     'f1-score': 0.631689049807738,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.84,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8749999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5483870967741935,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.5396825396825397,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6635514018691588,\n",
       "    'macro avg': {'precision': 0.6720967741935484,\n",
       "     'recall': 0.6905336394302849,\n",
       "     'f1-score': 0.6801857864357863,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6520410009044317,\n",
       "     'recall': 0.6635514018691588,\n",
       "     'f1-score': 0.6567345686504564,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.43333333333333335,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.41935483870967744,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.43636363636363634,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6068198005698007,\n",
       "     'recall': 0.6289238193403298,\n",
       "     'f1-score': 0.6160572783427966,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.584080863753761,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5894359343374411,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4333333333333333,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7142857142857143,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7843137254901961,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.6096428571428572,\n",
       "     'recall': 0.6375445089955023,\n",
       "     'f1-score': 0.6205102495543672,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5912683578104139,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.5964795008912657,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7586206896551724,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8461538461538461,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5384615384615384,\n",
       "     'recall': 0.65625,\n",
       "     'f1-score': 0.5915492957746479,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5263157894736842,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.4166666666666667,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7441860465116279,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6448598130841121,\n",
       "    'macro avg': {'precision': 0.6558495043975987,\n",
       "     'recall': 0.6633128748125937,\n",
       "     'f1-score': 0.6496389637766972,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6387121774539722,\n",
       "     'recall': 0.6448598130841121,\n",
       "     'f1-score': 0.631689049807738,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.84,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8749999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5483870967741935,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.5396825396825397,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6635514018691588,\n",
       "    'macro avg': {'precision': 0.6720967741935484,\n",
       "     'recall': 0.6905336394302849,\n",
       "     'f1-score': 0.6801857864357863,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6520410009044317,\n",
       "     'recall': 0.6635514018691588,\n",
       "     'f1-score': 0.6567345686504564,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial', solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.43333333333333335,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.41935483870967744,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4285714285714286,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.6000534188034188,\n",
       "     'recall': 0.6180542541229386,\n",
       "     'f1-score': 0.6079867774151528,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5773044971643102,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.582059865813175,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7037037037037037,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.76,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.42857142857142855,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.39999999999999997,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4285714285714286,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5841798941798941,\n",
       "     'recall': 0.6102417541229386,\n",
       "     'f1-score': 0.5950595238095238,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5632556989566335,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5693168669336894,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.6086956521739131,\n",
       "     'f1-score': 0.6363636363636365,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.43137254901960786,\n",
       "     'recall': 0.6875,\n",
       "     'f1-score': 0.5301204819277109,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.29411764705882354,\n",
       "     'recall': 0.1724137931034483,\n",
       "     'f1-score': 0.2173913043478261,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.5217391304347826,\n",
       "     'f1-score': 0.5853658536585366,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.4953271028037383,\n",
       "    'macro avg': {'precision': 0.5147058823529412,\n",
       "     'recall': 0.49758714392803605,\n",
       "     'f1-score': 0.49231031907442757,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.4953271028037383,\n",
       "     'recall': 0.4953271028037383,\n",
       "     'f1-score': 0.48007459362881943,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7857142857142857,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8627450980392156,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5357142857142857,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.5,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.38461538461538464,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.3636363636363637,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.606510989010989,\n",
       "     'recall': 0.6381770052473763,\n",
       "     'f1-score': 0.6190953654188949,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5881133819451575,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.5947531943958552,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial', penalty='l1',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4666666666666667,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.45161290322580644,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.43636363636363634,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.615153133903134,\n",
       "     'recall': 0.6367363193403298,\n",
       "     'f1-score': 0.6241217944718288,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5940497111057859,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.5990832059684329,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5832228116710875,\n",
       "     'recall': 0.6094335644677662,\n",
       "     'f1-score': 0.5943124790899966,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5628919903815166,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5692786322434596,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7586206896551724,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8461538461538461,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5384615384615384,\n",
       "     'recall': 0.65625,\n",
       "     'f1-score': 0.5915492957746479,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5263157894736842,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.4166666666666667,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7441860465116279,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6448598130841121,\n",
       "    'macro avg': {'precision': 0.6558495043975987,\n",
       "     'recall': 0.6633128748125937,\n",
       "     'f1-score': 0.6496389637766972,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6387121774539722,\n",
       "     'recall': 0.6448598130841121,\n",
       "     'f1-score': 0.631689049807738,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.84,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8749999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5483870967741935,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.5396825396825397,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6635514018691588,\n",
       "    'macro avg': {'precision': 0.6720967741935484,\n",
       "     'recall': 0.6905336394302849,\n",
       "     'f1-score': 0.6801857864357863,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6520410009044317,\n",
       "     'recall': 0.6635514018691588,\n",
       "     'f1-score': 0.6567345686504564,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4285714285714286,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6054877689360448,\n",
       "     'recall': 0.6289238193403298,\n",
       "     'f1-score': 0.6156985335117654,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5832338707233969,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5892687778344063,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5832228116710875,\n",
       "     'recall': 0.6094335644677662,\n",
       "     'f1-score': 0.5943124790899966,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5628919903815166,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5692786322434596,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7586206896551724,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8461538461538461,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5384615384615384,\n",
       "     'recall': 0.65625,\n",
       "     'f1-score': 0.5915492957746479,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5263157894736842,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.4166666666666667,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7441860465116279,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6448598130841121,\n",
       "    'macro avg': {'precision': 0.6558495043975987,\n",
       "     'recall': 0.6633128748125937,\n",
       "     'f1-score': 0.6496389637766972,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6387121774539722,\n",
       "     'recall': 0.6448598130841121,\n",
       "     'f1-score': 0.631689049807738,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7333333333333333,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8301886792452831,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5384615384615384,\n",
       "     'recall': 0.65625,\n",
       "     'f1-score': 0.5915492957746479,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.47368421052631576,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.375,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7894736842105263,\n",
       "     'recall': 0.6521739130434783,\n",
       "     'f1-score': 0.7142857142857143,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6261682242990654,\n",
       "    'macro avg': {'precision': 0.6337381916329284,\n",
       "     'recall': 0.64382261994003,\n",
       "     'f1-score': 0.6277559223264113,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.616749277939637,\n",
       "     'recall': 0.6261682242990654,\n",
       "     'f1-score': 0.6105372758504829,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.7924528301886793,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4722222222222222,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.4999999999999999,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.36363636363636365,\n",
       "     'recall': 0.27586206896551724,\n",
       "     'f1-score': 0.3137254901960784,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7894736842105263,\n",
       "     'recall': 0.6521739130434783,\n",
       "     'f1-score': 0.7142857142857143,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5700934579439252,\n",
       "    'macro avg': {'precision': 0.5813330675172781,\n",
       "     'recall': 0.5930823650674664,\n",
       "     'f1-score': 0.5801160086676179,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5599482279757735,\n",
       "     'recall': 0.5700934579439252,\n",
       "     'f1-score': 0.5584394928840872,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4634146341463415,\n",
       "     'recall': 0.59375,\n",
       "     'f1-score': 0.5205479452054794,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.34782608695652173,\n",
       "     'recall': 0.27586206896551724,\n",
       "     'f1-score': 0.3076923076923077,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8125,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.6666666666666667,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5607476635514018,\n",
       "    'macro avg': {'precision': 0.591120365460901,\n",
       "     'recall': 0.5760986694152923,\n",
       "     'f1-score': 0.5737267298911135,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5667360920697112,\n",
       "     'recall': 0.5607476635514018,\n",
       "     'f1-score': 0.5543359299344448,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.47619047619047616,\n",
       "     'recall': 0.625,\n",
       "     'f1-score': 0.5405405405405405,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3333333333333333,\n",
       "     'recall': 0.2413793103448276,\n",
       "     'f1-score': 0.28,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7222222222222222,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.6341463414634146,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5420560747663551,\n",
       "    'macro avg': {'precision': 0.5560134310134309,\n",
       "     'recall': 0.5535513493253373,\n",
       "     'f1-score': 0.5473451898887438,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5368126162518685,\n",
       "     'recall': 0.5420560747663551,\n",
       "     'f1-score': 0.5317815171460682,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.6086956521739131,\n",
       "     'f1-score': 0.6363636363636365,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.43137254901960786,\n",
       "     'recall': 0.6875,\n",
       "     'f1-score': 0.5301204819277109,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.29411764705882354,\n",
       "     'recall': 0.1724137931034483,\n",
       "     'f1-score': 0.2173913043478261,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.5217391304347826,\n",
       "     'f1-score': 0.5853658536585366,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.4953271028037383,\n",
       "    'macro avg': {'precision': 0.5147058823529412,\n",
       "     'recall': 0.49758714392803605,\n",
       "     'f1-score': 0.49231031907442757,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.4953271028037383,\n",
       "     'recall': 0.4953271028037383,\n",
       "     'f1-score': 0.48007459362881943,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.84,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8749999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5483870967741935,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.5396825396825397,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6635514018691588,\n",
       "    'macro avg': {'precision': 0.6720967741935484,\n",
       "     'recall': 0.6905336394302849,\n",
       "     'f1-score': 0.6801857864357863,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6520410009044317,\n",
       "     'recall': 0.6635514018691588,\n",
       "     'f1-score': 0.6567345686504564,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8076923076923077,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8571428571428572,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.53125,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.53125,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.37735849056603776,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6389022435897436,\n",
       "     'recall': 0.6646715704647677,\n",
       "     'f1-score': 0.6497711702605571,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.61738557392763,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6245266224987616,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.2, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.84,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8749999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.53125,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.53125,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.3703703703703704,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6428125,\n",
       "     'recall': 0.6646715704647677,\n",
       "     'f1-score': 0.6524884259259259,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6198130841121496,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6264710972654898,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.4, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8076923076923077,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8571428571428572,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5806451612903226,\n",
       "     'recall': 0.5625,\n",
       "     'f1-score': 0.5714285714285715,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.38461538461538464,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.3636363636363637,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7659574468085107,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6261682242990654,\n",
       "    'macro avg': {'precision': 0.6307382133995038,\n",
       "     'recall': 0.6507449400299851,\n",
       "     'f1-score': 0.6395413097540759,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6127234989912108,\n",
       "     'recall': 0.6261682242990654,\n",
       "     'f1-score': 0.6183408955331804,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.6, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7857142857142857,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8627450980392156,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5555555555555556,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.5084745762711864,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.37037037037037035,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.35714285714285715,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.607910052910053,\n",
       "     'recall': 0.6381770052473763,\n",
       "     'f1-score': 0.6195906328633148,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5901864214013747,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.5955277247918017,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.8, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7857142857142857,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8627450980392156,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5357142857142857,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.5,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.38461538461538464,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.3636363636363637,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.606510989010989,\n",
       "     'recall': 0.6381770052473763,\n",
       "     'f1-score': 0.6190953654188949,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5881133819451575,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.5947531943958552,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=1.0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4285714285714286,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6054877689360448,\n",
       "     'recall': 0.6289238193403298,\n",
       "     'f1-score': 0.6156985335117654,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5832338707233969,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5892687778344063,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7037037037037037,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.76,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.5937641222123982,\n",
       "     'recall': 0.6203031296851574,\n",
       "     'f1-score': 0.6048907103825136,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5719555471086247,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5783739339155304,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4333333333333333,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7037037037037037,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.76,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.5900742775742776,\n",
       "     'recall': 0.6203031296851574,\n",
       "     'f1-score': 0.6024149659863947,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5701295934940794,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5768427744929747,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.8333333333333334,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.851063829787234,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4827586206896552,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.4590163934426229,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4285714285714286,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.616822429906542,\n",
       "    'macro avg': {'precision': 0.6253192848020435,\n",
       "     'recall': 0.6476058845577211,\n",
       "     'f1-score': 0.6346629129503214,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.603185686492164,\n",
       "     'recall': 0.616822429906542,\n",
       "     'f1-score': 0.6083323748022592,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.8333333333333334,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.851063829787234,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4838709677419355,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.43636363636363634,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6261682242990654,\n",
       "    'macro avg': {'precision': 0.633903133903134,\n",
       "     'recall': 0.6554183845577211,\n",
       "     'f1-score': 0.6428246084732014,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6129749447506457,\n",
       "     'recall': 0.6261682242990654,\n",
       "     'f1-score': 0.6178774253027456,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4666666666666667,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.45161290322580644,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.43636363636363634,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.615153133903134,\n",
       "     'recall': 0.6367363193403298,\n",
       "     'f1-score': 0.6241217944718288,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5940497111057859,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.5990832059684329,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5832228116710875,\n",
       "     'recall': 0.6094335644677662,\n",
       "     'f1-score': 0.5943124790899966,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5628919903815166,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5692786322434596,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5832228116710875,\n",
       "     'recall': 0.6094335644677662,\n",
       "     'f1-score': 0.5943124790899966,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5628919903815166,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5692786322434596,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5832228116710875,\n",
       "     'recall': 0.6094335644677662,\n",
       "     'f1-score': 0.5943124790899966,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5628919903815166,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5692786322434596,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5832228116710875,\n",
       "     'recall': 0.6094335644677662,\n",
       "     'f1-score': 0.5943124790899966,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5628919903815166,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5692786322434596,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5832228116710875,\n",
       "     'recall': 0.6094335644677662,\n",
       "     'f1-score': 0.5943124790899966,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5628919903815166,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5692786322434596,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5832228116710875,\n",
       "     'recall': 0.6094335644677662,\n",
       "     'f1-score': 0.5943124790899966,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5628919903815166,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5692786322434596,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7586206896551724,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8461538461538461,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5384615384615384,\n",
       "     'recall': 0.65625,\n",
       "     'f1-score': 0.5915492957746479,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5263157894736842,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.4166666666666667,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7441860465116279,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6448598130841121,\n",
       "    'macro avg': {'precision': 0.6558495043975987,\n",
       "     'recall': 0.6633128748125937,\n",
       "     'f1-score': 0.6496389637766972,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6387121774539722,\n",
       "     'recall': 0.6448598130841121,\n",
       "     'f1-score': 0.631689049807738,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.84,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8749999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5483870967741935,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.5396825396825397,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6635514018691588,\n",
       "    'macro avg': {'precision': 0.6720967741935484,\n",
       "     'recall': 0.6905336394302849,\n",
       "     'f1-score': 0.6801857864357863,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6520410009044317,\n",
       "     'recall': 0.6635514018691588,\n",
       "     'f1-score': 0.6567345686504564,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.43333333333333335,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.41935483870967744,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.43636363636363634,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6068198005698007,\n",
       "     'recall': 0.6289238193403298,\n",
       "     'f1-score': 0.6160572783427966,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.584080863753761,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5894359343374411,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4333333333333333,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7142857142857143,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7843137254901961,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.6096428571428572,\n",
       "     'recall': 0.6375445089955023,\n",
       "     'f1-score': 0.6205102495543672,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5912683578104139,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.5964795008912657,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None}],\n",
       " 'KFold': [{'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.6808510638297872,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.37777777777777777,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.4415584415584416,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.32142857142857145,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.31578947368421056,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.5,\n",
       "     'recall': 0.21739130434782608,\n",
       "     'f1-score': 0.30303030303030304,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.4392523364485981,\n",
       "    'macro avg': {'precision': 0.4664682539682539,\n",
       "     'recall': 0.4386595764617691,\n",
       "     'f1-score': 0.4353073205256856,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.45087524106215693,\n",
       "     'recall': 0.4392523364485981,\n",
       "     'f1-score': 0.42913118041583476,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7727272727272727,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7555555555555555,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.38095238095238093,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.4324324324324324,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3793103448275862,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.3793103448275862,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.5714285714285714,\n",
       "     'recall': 0.34782608695652173,\n",
       "     'f1-score': 0.4324324324324324,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.48598130841121495,\n",
       "    'macro avg': {'precision': 0.5261046424839528,\n",
       "     'recall': 0.4915667166416791,\n",
       "     'f1-score': 0.4999326913120017,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5056641178136505,\n",
       "     'recall': 0.48598130841121495,\n",
       "     'f1-score': 0.48749122954730423,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7391304347826086,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7391304347826085,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.3783783783783784,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.40579710144927533,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3793103448275862,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.3793103448275862,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6111111111111112,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5365853658536586,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.4953271028037383,\n",
       "    'macro avg': {'precision': 0.5269825672749211,\n",
       "     'recall': 0.508550412293853,\n",
       "     'f1-score': 0.5152058117282822,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5062024641463895,\n",
       "     'recall': 0.4953271028037383,\n",
       "     'f1-score': 0.49838290337393415,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7083333333333334,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.723404255319149,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.38235294117647056,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.393939393939394,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.40625,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.5294117647058824,\n",
       "     'recall': 0.391304347826087,\n",
       "     'f1-score': 0.45,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.48598130841121495,\n",
       "    'macro avg': {'precision': 0.5065870098039216,\n",
       "     'recall': 0.4962401611694153,\n",
       "     'f1-score': 0.49839328936381605,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.4905110408649441,\n",
       "     'recall': 0.48598130841121495,\n",
       "     'f1-score': 0.4855608805243547,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.6808510638297872,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.37777777777777777,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.4415584415584416,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.32142857142857145,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.31578947368421056,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.5,\n",
       "     'recall': 0.21739130434782608,\n",
       "     'f1-score': 0.30303030303030304,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.4392523364485981,\n",
       "    'macro avg': {'precision': 0.4664682539682539,\n",
       "     'recall': 0.4386595764617691,\n",
       "     'f1-score': 0.4353073205256856,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.45087524106215693,\n",
       "     'recall': 0.4392523364485981,\n",
       "     'f1-score': 0.42913118041583476,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7727272727272727,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7555555555555555,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.38095238095238093,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.4324324324324324,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3793103448275862,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.3793103448275862,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.5714285714285714,\n",
       "     'recall': 0.34782608695652173,\n",
       "     'f1-score': 0.4324324324324324,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.48598130841121495,\n",
       "    'macro avg': {'precision': 0.5261046424839528,\n",
       "     'recall': 0.4915667166416791,\n",
       "     'f1-score': 0.4999326913120017,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5056641178136505,\n",
       "     'recall': 0.48598130841121495,\n",
       "     'f1-score': 0.48749122954730423,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial', solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.631578947368421,\n",
       "     'recall': 0.5217391304347826,\n",
       "     'f1-score': 0.5714285714285715,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5233644859813084,\n",
       "    'macro avg': {'precision': 0.5439132553606238,\n",
       "     'recall': 0.5381020427286357,\n",
       "     'f1-score': 0.5388655462184874,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5255557377347835,\n",
       "     'recall': 0.5233644859813084,\n",
       "     'f1-score': 0.5224613209769889,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.41791044776119407,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.39285714285714285,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.3859649122807017,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6111111111111112,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5365853658536586,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5046728971962616,\n",
       "    'macro avg': {'precision': 0.5240689865689866,\n",
       "     'recall': 0.5194199775112444,\n",
       "     'f1-score': 0.5187886508616437,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5062756039391554,\n",
       "     'recall': 0.5046728971962616,\n",
       "     'f1-score': 0.5028555082505249,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.08333333333333333,\n",
       "     'recall': 0.043478260869565216,\n",
       "     'f1-score': 0.057142857142857134,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.0,\n",
       "     'recall': 0.0,\n",
       "     'f1-score': 0.0,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.027777777777777776,\n",
       "     'recall': 0.034482758620689655,\n",
       "     'f1-score': 0.030769230769230767,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.4,\n",
       "     'recall': 0.17391304347826086,\n",
       "     'f1-score': 0.24242424242424243,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.056074766355140186,\n",
       "    'macro avg': {'precision': 0.12777777777777777,\n",
       "     'recall': 0.06296851574212893,\n",
       "     'f1-score': 0.08258408258408259,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.11142263759086189,\n",
       "     'recall': 0.056074766355140186,\n",
       "     'f1-score': 0.0727322521715045,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7441860465116279,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.40476190476190477,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.4594594594594595,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3448275862068966,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.3448275862068966,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.625,\n",
       "     'recall': 0.43478260869565216,\n",
       "     'f1-score': 0.5128205128205128,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.4953271028037383,\n",
       "    'macro avg': {'precision': 0.5436473727422004,\n",
       "     'recall': 0.501628092203898,\n",
       "     'f1-score': 0.5153234012496242,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5208166444147753,\n",
       "     'recall': 0.4953271028037383,\n",
       "     'f1-score': 0.501064052031233,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial', penalty='l1',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.42857142857142855,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4477611940298507,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.41379310344827586,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.41379310344827586,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6842105263157895,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.6190476190476191,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5514018691588785,\n",
       "    'macro avg': {'precision': 0.5795604312505401,\n",
       "     'recall': 0.5684618628185907,\n",
       "     'f1-score': 0.5722781387059045,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.557565057503572,\n",
       "     'recall': 0.5514018691588785,\n",
       "     'f1-score': 0.5529177395130984,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6111111111111112,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5365853658536586,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.514018691588785,\n",
       "    'macro avg': {'precision': 0.5318732193732194,\n",
       "     'recall': 0.5272324775112444,\n",
       "     'f1-score': 0.5263282142125143,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5152035572596321,\n",
       "     'recall': 0.514018691588785,\n",
       "     'f1-score': 0.5116815588783952,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.6808510638297872,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.37777777777777777,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.4415584415584416,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.32142857142857145,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.31578947368421056,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.5,\n",
       "     'recall': 0.21739130434782608,\n",
       "     'f1-score': 0.30303030303030304,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.4392523364485981,\n",
       "    'macro avg': {'precision': 0.4664682539682539,\n",
       "     'recall': 0.4386595764617691,\n",
       "     'f1-score': 0.4353073205256856,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.45087524106215693,\n",
       "     'recall': 0.4392523364485981,\n",
       "     'f1-score': 0.42913118041583476,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8181818181818182,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.8,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.41025641025641024,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.4507042253521127,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3870967741935484,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.39999999999999997,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6,\n",
       "     'recall': 0.391304347826087,\n",
       "     'f1-score': 0.47368421052631576,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.514018691588785,\n",
       "    'macro avg': {'precision': 0.5538837506579443,\n",
       "     'recall': 0.5219265367316341,\n",
       "     'f1-score': 0.5310971089696072,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5324504055887836,\n",
       "     'recall': 0.514018691588785,\n",
       "     'f1-score': 0.5169838509661016,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.631578947368421,\n",
       "     'recall': 0.5217391304347826,\n",
       "     'f1-score': 0.5714285714285715,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5233644859813084,\n",
       "    'macro avg': {'precision': 0.5439132553606238,\n",
       "     'recall': 0.5381020427286357,\n",
       "     'f1-score': 0.5388655462184874,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5255557377347835,\n",
       "     'recall': 0.5233644859813084,\n",
       "     'f1-score': 0.5224613209769889,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6111111111111112,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5365853658536586,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.514018691588785,\n",
       "    'macro avg': {'precision': 0.5318732193732194,\n",
       "     'recall': 0.5272324775112444,\n",
       "     'f1-score': 0.5263282142125143,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5152035572596321,\n",
       "     'recall': 0.514018691588785,\n",
       "     'f1-score': 0.5116815588783952,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.6808510638297872,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.37777777777777777,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.4415584415584416,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.32142857142857145,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.31578947368421056,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.5,\n",
       "     'recall': 0.21739130434782608,\n",
       "     'f1-score': 0.30303030303030304,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.4392523364485981,\n",
       "    'macro avg': {'precision': 0.4664682539682539,\n",
       "     'recall': 0.4386595764617691,\n",
       "     'f1-score': 0.4353073205256856,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.45087524106215693,\n",
       "     'recall': 0.4392523364485981,\n",
       "     'f1-score': 0.42913118041583476,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.6153846153846154,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.6530612244897959,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.36363636363636365,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.4210526315789474,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.25,\n",
       "     'recall': 0.2413793103448276,\n",
       "     'f1-score': 0.24561403508771928,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.17391304347826086,\n",
       "     'f1-score': 0.25,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.40186915887850466,\n",
       "    'macro avg': {'precision': 0.4183663558663559,\n",
       "     'recall': 0.402736131934033,\n",
       "     'f1-score': 0.3924319727891157,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.4043217945087104,\n",
       "     'recall': 0.40186915887850466,\n",
       "     'f1-score': 0.3866065363676213,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.5,\n",
       "     'recall': 0.391304347826087,\n",
       "     'f1-score': 0.4390243902439025,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.24489795918367346,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.2962962962962962,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.1935483870967742,\n",
       "     'recall': 0.20689655172413793,\n",
       "     'f1-score': 0.19999999999999998,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.17391304347826086,\n",
       "     'f1-score': 0.25,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.2897196261682243,\n",
       "    'macro avg': {'precision': 0.34572269768122305,\n",
       "     'recall': 0.2867784857571214,\n",
       "     'f1-score': 0.29633017163504966,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.3287089732888432,\n",
       "     'recall': 0.2897196261682243,\n",
       "     'f1-score': 0.29092563044010505,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.18181818181818182,\n",
       "     'recall': 0.08695652173913043,\n",
       "     'f1-score': 0.1176470588235294,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.18181818181818182,\n",
       "     'recall': 0.3125,\n",
       "     'f1-score': 0.2298850574712644,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.09090909090909091,\n",
       "     'recall': 0.10344827586206896,\n",
       "     'f1-score': 0.0967741935483871,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.375,\n",
       "     'recall': 0.13043478260869565,\n",
       "     'f1-score': 0.19354838709677416,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.16822429906542055,\n",
       "    'macro avg': {'precision': 0.20738636363636365,\n",
       "     'recall': 0.15833489505247378,\n",
       "     'f1-score': 0.15946367423498875,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.19870433305012744,\n",
       "     'recall': 0.16822429906542055,\n",
       "     'f1-score': 0.16187167016963244,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.08333333333333333,\n",
       "     'recall': 0.043478260869565216,\n",
       "     'f1-score': 0.057142857142857134,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.0784313725490196,\n",
       "     'recall': 0.125,\n",
       "     'f1-score': 0.0963855421686747,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.08571428571428572,\n",
       "     'recall': 0.10344827586206896,\n",
       "     'f1-score': 0.09375,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.17391304347826086,\n",
       "     'f1-score': 0.25,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.11214953271028037,\n",
       "    'macro avg': {'precision': 0.17298085901027077,\n",
       "     'recall': 0.11145989505247376,\n",
       "     'f1-score': 0.12431959982788296,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.16013464575861494,\n",
       "     'recall': 0.11214953271028037,\n",
       "     'f1-score': 0.12025582302507762,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.08333333333333333,\n",
       "     'recall': 0.043478260869565216,\n",
       "     'f1-score': 0.057142857142857134,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.0,\n",
       "     'recall': 0.0,\n",
       "     'f1-score': 0.0,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.027777777777777776,\n",
       "     'recall': 0.034482758620689655,\n",
       "     'f1-score': 0.030769230769230767,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.4,\n",
       "     'recall': 0.17391304347826086,\n",
       "     'f1-score': 0.24242424242424243,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.056074766355140186,\n",
       "    'macro avg': {'precision': 0.12777777777777777,\n",
       "     'recall': 0.06296851574212893,\n",
       "     'f1-score': 0.08258408258408259,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.11142263759086189,\n",
       "     'recall': 0.056074766355140186,\n",
       "     'f1-score': 0.0727322521715045,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8181818181818182,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.8,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.41025641025641024,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.4507042253521127,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3870967741935484,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.39999999999999997,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6,\n",
       "     'recall': 0.391304347826087,\n",
       "     'f1-score': 0.47368421052631576,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.514018691588785,\n",
       "    'macro avg': {'precision': 0.5538837506579443,\n",
       "     'recall': 0.5219265367316341,\n",
       "     'f1-score': 0.5310971089696072,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5324504055887836,\n",
       "     'recall': 0.514018691588785,\n",
       "     'f1-score': 0.5169838509661016,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8260869565217391,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8260869565217391,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.42105263157894735,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.45714285714285713,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3870967741935484,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.39999999999999997,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6,\n",
       "     'recall': 0.391304347826087,\n",
       "     'f1-score': 0.47368421052631576,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5233644859813084,\n",
       "    'macro avg': {'precision': 0.5585590905735588,\n",
       "     'recall': 0.5327961019490255,\n",
       "     'f1-score': 0.539228506047728,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5373784174031703,\n",
       "     'recall': 0.5233644859813084,\n",
       "     'f1-score': 0.5245168997259504,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.2, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8571428571428571,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.8181818181818182,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.5625,\n",
       "     'f1-score': 0.5070422535211268,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3870967741935484,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.39999999999999997,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6875,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5641025641025642,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5514018691588785,\n",
       "    'macro avg': {'precision': 0.5983195232187167,\n",
       "     'recall': 0.5592906671664167,\n",
       "     'f1-score': 0.5723316589513773,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5749703078049475,\n",
       "     'recall': 0.5514018691588785,\n",
       "     'f1-score': 0.5571765692076341,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.4, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.85,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7906976744186046,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.42857142857142855,\n",
       "     'recall': 0.5625,\n",
       "     'f1-score': 0.4864864864864864,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3448275862068966,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.3448275862068966,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6875,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5641025641025642,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5233644859813084,\n",
       "    'macro avg': {'precision': 0.5777247536945813,\n",
       "     'recall': 0.5311797226386806,\n",
       "     'f1-score': 0.546528577803638,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5521194926568758,\n",
       "     'recall': 0.5233644859813084,\n",
       "     'f1-score': 0.5301679724631257,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.6, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7894736842105263,\n",
       "     'recall': 0.6521739130434783,\n",
       "     'f1-score': 0.7142857142857143,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.38095238095238093,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.4324324324324324,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3225806451612903,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.33333333333333337,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6,\n",
       "     'recall': 0.391304347826087,\n",
       "     'f1-score': 0.47368421052631576,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.4672897196261682,\n",
       "    'macro avg': {'precision': 0.5232516775810494,\n",
       "     'recall': 0.47207646176911544,\n",
       "     'f1-score': 0.4884339226444489,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5000299966074365,\n",
       "     'recall': 0.4672897196261682,\n",
       "     'f1-score': 0.4750262876185159,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.8, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7619047619047619,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7272727272727272,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.3902439024390244,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.4383561643835617,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3448275862068966,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.3448275862068966,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.625,\n",
       "     'recall': 0.43478260869565216,\n",
       "     'f1-score': 0.5128205128205128,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.48598130841121495,\n",
       "    'macro avg': {'precision': 0.5304940626376706,\n",
       "     'recall': 0.49381559220389803,\n",
       "     'f1-score': 0.5058192476709246,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5082861159052178,\n",
       "     'recall': 0.48598130841121495,\n",
       "     'f1-score': 0.491117212919799,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=1.0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.631578947368421,\n",
       "     'recall': 0.5217391304347826,\n",
       "     'f1-score': 0.5714285714285715,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5233644859813084,\n",
       "    'macro avg': {'precision': 0.5439132553606238,\n",
       "     'recall': 0.5381020427286357,\n",
       "     'f1-score': 0.5388655462184874,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5255557377347835,\n",
       "     'recall': 0.5233644859813084,\n",
       "     'f1-score': 0.5224613209769889,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.631578947368421,\n",
       "     'recall': 0.5217391304347826,\n",
       "     'f1-score': 0.5714285714285715,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5233644859813084,\n",
       "    'macro avg': {'precision': 0.5439132553606238,\n",
       "     'recall': 0.5381020427286357,\n",
       "     'f1-score': 0.5388655462184874,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5255557377347835,\n",
       "     'recall': 0.5233644859813084,\n",
       "     'f1-score': 0.5224613209769889,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7659574468085107,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.39285714285714285,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.3859649122807017,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.631578947368421,\n",
       "     'recall': 0.5217391304347826,\n",
       "     'f1-score': 0.5714285714285715,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5233644859813084,\n",
       "    'macro avg': {'precision': 0.5477756892230576,\n",
       "     'recall': 0.5381020427286357,\n",
       "     'f1-score': 0.5411318502765048,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5280608062211605,\n",
       "     'recall': 0.5233644859813084,\n",
       "     'f1-score': 0.5240234386394091,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.42857142857142855,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4477611940298507,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.39285714285714285,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.3859649122807017,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.631578947368421,\n",
       "     'recall': 0.5217391304347826,\n",
       "     'f1-score': 0.5714285714285715,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5327102803738317,\n",
       "    'macro avg': {'precision': 0.553251879699248,\n",
       "     'recall': 0.5489716079460271,\n",
       "     'f1-score': 0.5492053361014476,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5337706415571639,\n",
       "     'recall': 0.5327102803738317,\n",
       "     'f1-score': 0.5315189826288417,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4117647058823529,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.42424242424242425,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.36666666666666664,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.3728813559322034,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.5217391304347826,\n",
       "     'f1-score': 0.5853658536585366,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5233644859813084,\n",
       "    'macro avg': {'precision': 0.5512745098039216,\n",
       "     'recall': 0.5411591079460271,\n",
       "     'f1-score': 0.5435390751249578,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5291881986439436,\n",
       "     'recall': 0.5233644859813084,\n",
       "     'f1-score': 0.5239351856567397,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.42857142857142855,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4477611940298507,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.41379310344827586,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.41379310344827586,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6842105263157895,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.6190476190476191,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5514018691588785,\n",
       "    'macro avg': {'precision': 0.5795604312505401,\n",
       "     'recall': 0.5684618628185907,\n",
       "     'f1-score': 0.5722781387059045,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.557565057503572,\n",
       "     'recall': 0.5514018691588785,\n",
       "     'f1-score': 0.5529177395130984,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6111111111111112,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5365853658536586,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.514018691588785,\n",
       "    'macro avg': {'precision': 0.5318732193732194,\n",
       "     'recall': 0.5272324775112444,\n",
       "     'f1-score': 0.5263282142125143,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5152035572596321,\n",
       "     'recall': 0.514018691588785,\n",
       "     'f1-score': 0.5116815588783952,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6111111111111112,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5365853658536586,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.514018691588785,\n",
       "    'macro avg': {'precision': 0.5318732193732194,\n",
       "     'recall': 0.5272324775112444,\n",
       "     'f1-score': 0.5263282142125143,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5152035572596321,\n",
       "     'recall': 0.514018691588785,\n",
       "     'f1-score': 0.5116815588783952,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6111111111111112,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5365853658536586,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.514018691588785,\n",
       "    'macro avg': {'precision': 0.5318732193732194,\n",
       "     'recall': 0.5272324775112444,\n",
       "     'f1-score': 0.5263282142125143,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5152035572596321,\n",
       "     'recall': 0.514018691588785,\n",
       "     'f1-score': 0.5116815588783952,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6111111111111112,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5365853658536586,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.514018691588785,\n",
       "    'macro avg': {'precision': 0.5318732193732194,\n",
       "     'recall': 0.5272324775112444,\n",
       "     'f1-score': 0.5263282142125143,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5152035572596321,\n",
       "     'recall': 0.514018691588785,\n",
       "     'f1-score': 0.5116815588783952,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6111111111111112,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5365853658536586,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.514018691588785,\n",
       "    'macro avg': {'precision': 0.5318732193732194,\n",
       "     'recall': 0.5272324775112444,\n",
       "     'f1-score': 0.5263282142125143,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5152035572596321,\n",
       "     'recall': 0.514018691588785,\n",
       "     'f1-score': 0.5116815588783952,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6111111111111112,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5365853658536586,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.514018691588785,\n",
       "    'macro avg': {'precision': 0.5318732193732194,\n",
       "     'recall': 0.5272324775112444,\n",
       "     'f1-score': 0.5263282142125143,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5152035572596321,\n",
       "     'recall': 0.514018691588785,\n",
       "     'f1-score': 0.5116815588783952,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.6808510638297872,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.37777777777777777,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.4415584415584416,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.32142857142857145,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.31578947368421056,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.5,\n",
       "     'recall': 0.21739130434782608,\n",
       "     'f1-score': 0.30303030303030304,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.4392523364485981,\n",
       "    'macro avg': {'precision': 0.4664682539682539,\n",
       "     'recall': 0.4386595764617691,\n",
       "     'f1-score': 0.4353073205256856,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.45087524106215693,\n",
       "     'recall': 0.4392523364485981,\n",
       "     'f1-score': 0.42913118041583476,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7727272727272727,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7555555555555555,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.38095238095238093,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.4324324324324324,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3793103448275862,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.3793103448275862,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.5714285714285714,\n",
       "     'recall': 0.34782608695652173,\n",
       "     'f1-score': 0.4324324324324324,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.48598130841121495,\n",
       "    'macro avg': {'precision': 0.5261046424839528,\n",
       "     'recall': 0.4915667166416791,\n",
       "     'f1-score': 0.4999326913120017,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5056641178136505,\n",
       "     'recall': 0.48598130841121495,\n",
       "     'f1-score': 0.48749122954730423,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7391304347826086,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7391304347826085,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.3783783783783784,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.40579710144927533,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3793103448275862,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.3793103448275862,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6111111111111112,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5365853658536586,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.4953271028037383,\n",
       "    'macro avg': {'precision': 0.5269825672749211,\n",
       "     'recall': 0.508550412293853,\n",
       "     'f1-score': 0.5152058117282822,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5062024641463895,\n",
       "     'recall': 0.4953271028037383,\n",
       "     'f1-score': 0.49838290337393415,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7083333333333334,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.723404255319149,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.38235294117647056,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.393939393939394,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.40625,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.5294117647058824,\n",
       "     'recall': 0.391304347826087,\n",
       "     'f1-score': 0.45,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.48598130841121495,\n",
       "    'macro avg': {'precision': 0.5065870098039216,\n",
       "     'recall': 0.4962401611694153,\n",
       "     'f1-score': 0.49839328936381605,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.4905110408649441,\n",
       "     'recall': 0.48598130841121495,\n",
       "     'f1-score': 0.4855608805243547,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None}],\n",
       " 'StratifiedKFold': [{'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7586206896551724,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8461538461538461,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5405405405405406,\n",
       "     'recall': 0.625,\n",
       "     'f1-score': 0.5797101449275363,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.40816326530612246,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7619047619047619,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7272727272727272,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6402664980251187,\n",
       "     'recall': 0.6555003748125937,\n",
       "     'f1-score': 0.640324995915058,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6240129222726708,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6222081357043916,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.84,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8749999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4838709677419355,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.48148148148148145,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4642857142857143,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6453703703703704,\n",
       "     'recall': 0.6640390742128935,\n",
       "     'f1-score': 0.6537058371735791,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6239529248875043,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6287989721061774,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.8333333333333334,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.851063829787234,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.41379310344827586,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4827586206896552,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.4827586206896552,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7142857142857143,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7843137254901961,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.616822429906542,\n",
       "    'macro avg': {'precision': 0.6229790324617911,\n",
       "     'recall': 0.6492222638680659,\n",
       "     'f1-score': 0.6329823198538403,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6015370921912979,\n",
       "     'recall': 0.616822429906542,\n",
       "     'f1-score': 0.6061220848759413,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.8333333333333334,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.851063829787234,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.44,\n",
       "     'recall': 0.34375,\n",
       "     'f1-score': 0.3859649122807018,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4482758620689655,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6551724137931034,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7307692307692308,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.5941954022988506,\n",
       "     'recall': 0.6219195089955022,\n",
       "     'f1-score': 0.604018458726533,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5730432914383929,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5769442765026276,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7333333333333333,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8301886792452831,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5405405405405406,\n",
       "     'recall': 0.625,\n",
       "     'f1-score': 0.5797101449275363,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5263157894736842,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.4166666666666667,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7619047619047619,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7272727272727272,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6405236063130799,\n",
       "     'recall': 0.6555003748125937,\n",
       "     'f1-score': 0.6384595545280534,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6257096390888817,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6210810310367171,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.875,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8936170212765957,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4838709677419355,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6498214285714285,\n",
       "     'recall': 0.6640390742128935,\n",
       "     'f1-score': 0.6563237516405978,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6268157543391188,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6305931398679959,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial', solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7777777777777778,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.84,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4482758620689655,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7142857142857143,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7843137254901961,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6261682242990654,\n",
       "    'macro avg': {'precision': 0.623015873015873,\n",
       "     'recall': 0.6592836394302849,\n",
       "     'f1-score': 0.6363292150716086,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6057706571725263,\n",
       "     'recall': 0.6261682242990654,\n",
       "     'f1-score': 0.611337702631517,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.4067796610169491,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.48148148148148145,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4642857142857143,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7037037037037037,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.76,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.5997150997150997,\n",
       "     'recall': 0.6297320089955022,\n",
       "     'f1-score': 0.611847976478727,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5800250286231594,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5863247202888758,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7777777777777778,\n",
       "     'recall': 0.6086956521739131,\n",
       "     'f1-score': 0.6829268292682927,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.38596491228070173,\n",
       "     'recall': 0.6875,\n",
       "     'f1-score': 0.49438202247191015,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.38461538461538464,\n",
       "     'recall': 0.1724137931034483,\n",
       "     'f1-score': 0.23809523809523808,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.5789473684210527,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5238095238095238,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.48598130841121495,\n",
       "    'macro avg': {'precision': 0.5318263607737292,\n",
       "     'recall': 0.4867175787106447,\n",
       "     'f1-score': 0.4848034034112412,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5113028197140347,\n",
       "     'recall': 0.48598130841121495,\n",
       "     'f1-score': 0.4717749789219889,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5517241379310345,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5245901639344263,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.38461538461538464,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.3636363636363637,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7659574468085107,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.6090848806366047,\n",
       "     'recall': 0.6351199400299851,\n",
       "     'f1-score': 0.6194283465360017,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5916730707256005,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.5971078274629923,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial', penalty='l1',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7241379310344828,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8076923076923076,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.3125,\n",
       "     'f1-score': 0.35714285714285715,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.574349501073639,\n",
       "     'recall': 0.6141070089955023,\n",
       "     'f1-score': 0.5889173483158445,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5549146577989634,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.561976858547725,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.44,\n",
       "     'recall': 0.34375,\n",
       "     'f1-score': 0.3859649122807018,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4285714285714286,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.72,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5752777777777778,\n",
       "     'recall': 0.6132988193403298,\n",
       "     'f1-score': 0.5895164381542091,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5565628245067497,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.563370327963945,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7333333333333333,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8301886792452831,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5405405405405406,\n",
       "     'recall': 0.625,\n",
       "     'f1-score': 0.5797101449275363,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5263157894736842,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.4166666666666667,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7619047619047619,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7272727272727272,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6405236063130799,\n",
       "     'recall': 0.6555003748125937,\n",
       "     'f1-score': 0.6384595545280534,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6257096390888817,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6210810310367171,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.875,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8936170212765957,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4838709677419355,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6498214285714285,\n",
       "     'recall': 0.6640390742128935,\n",
       "     'f1-score': 0.6563237516405978,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6268157543391188,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6305931398679959,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4482758620689655,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.48148148148148145,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4642857142857143,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.616822429906542,\n",
       "    'macro avg': {'precision': 0.6155626780626781,\n",
       "     'recall': 0.6484140742128935,\n",
       "     'f1-score': 0.6279002980502546,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5983238810341613,\n",
       "     'recall': 0.616822429906542,\n",
       "     'f1-score': 0.6036170510743775,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.41379310344827586,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.48148148148148145,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4642857142857143,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.5963319088319088,\n",
       "     'recall': 0.6297320089955023,\n",
       "     'f1-score': 0.609075526762429,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5785539313576696,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5845308474662827,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7333333333333333,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8301886792452831,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5405405405405406,\n",
       "     'recall': 0.625,\n",
       "     'f1-score': 0.5797101449275363,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5263157894736842,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.4166666666666667,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7619047619047619,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7272727272727272,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6405236063130799,\n",
       "     'recall': 0.6555003748125937,\n",
       "     'f1-score': 0.6384595545280534,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6257096390888817,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6210810310367171,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7333333333333333,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8301886792452831,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.5625,\n",
       "     'f1-score': 0.5294117647058824,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.38095238095238093,\n",
       "     'recall': 0.27586206896551724,\n",
       "     'f1-score': 0.32,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7441860465116279,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6035714285714286,\n",
       "     'recall': 0.6226339955022488,\n",
       "     'f1-score': 0.6059466226156984,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5823765020026702,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5834747211495065,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7241379310344828,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8076923076923076,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.65625,\n",
       "     'f1-score': 0.5675675675675675,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.47368421052631576,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.375,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8235294117647058,\n",
       "     'recall': 0.6086956521739131,\n",
       "     'f1-score': 0.7,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.630337888331376,\n",
       "     'recall': 0.6220834895052474,\n",
       "     'f1-score': 0.6125649688149688,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6105905699966775,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.5954587405521985,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4878048780487805,\n",
       "     'recall': 0.625,\n",
       "     'f1-score': 0.547945205479452,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4090909090909091,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.35294117647058826,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7222222222222222,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.6341463414634146,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5970871946481703,\n",
       "     'recall': 0.5925318590704647,\n",
       "     'f1-score': 0.587839813506425,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5773533763048238,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5713123060815859,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4666666666666667,\n",
       "     'recall': 0.65625,\n",
       "     'f1-score': 0.5454545454545454,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.35294117647058826,\n",
       "     'recall': 0.20689655172413793,\n",
       "     'f1-score': 0.2608695652173913,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6,\n",
       "     'recall': 0.5217391304347826,\n",
       "     'f1-score': 0.5581395348837209,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5420560747663551,\n",
       "    'macro avg': {'precision': 0.5449019607843137,\n",
       "     'recall': 0.552743159670165,\n",
       "     'f1-score': 0.5390325780555811,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.527557265897013,\n",
       "     'recall': 0.5420560747663551,\n",
       "     'f1-score': 0.5239748175841936,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7368421052631579,\n",
       "     'recall': 0.6086956521739131,\n",
       "     'f1-score': 0.6666666666666666,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.39285714285714285,\n",
       "     'recall': 0.6875,\n",
       "     'f1-score': 0.5,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.38461538461538464,\n",
       "     'recall': 0.1724137931034483,\n",
       "     'f1-score': 0.23809523809523808,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.5789473684210527,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5238095238095238,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.48598130841121495,\n",
       "    'macro avg': {'precision': 0.5233155002891845,\n",
       "     'recall': 0.4867175787106447,\n",
       "     'f1-score': 0.4821428571428571,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5045647908412296,\n",
       "     'recall': 0.48598130841121495,\n",
       "     'f1-score': 0.46995994659546053,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.875,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8936170212765957,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4838709677419355,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6498214285714285,\n",
       "     'recall': 0.6640390742128935,\n",
       "     'f1-score': 0.6563237516405978,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6268157543391188,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6305931398679959,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.875,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8936170212765957,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.4666666666666667,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4482758620689655,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6481266578249337,\n",
       "     'recall': 0.6670961394302849,\n",
       "     'f1-score': 0.6562215201561181,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6244608195542775,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6286171497829595,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.2, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8076923076923077,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8571428571428572,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5172413793103449,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4918032786885246,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.42857142857142855,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.42105263157894735,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7659574468085107,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.616822429906542,\n",
       "    'macro avg': {'precision': 0.6258762788935204,\n",
       "     'recall': 0.6445488193403298,\n",
       "     'f1-score': 0.63398905355471,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6056749405927621,\n",
       "     'recall': 0.616822429906542,\n",
       "     'f1-score': 0.6100891422869505,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.4, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5357142857142857,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.5,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.42857142857142855,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.42105263157894735,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.616822429906542,\n",
       "    'macro avg': {'precision': 0.6241732804232805,\n",
       "     'recall': 0.6445488193403298,\n",
       "     'f1-score': 0.6323908174692049,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6057644760915788,\n",
       "     'recall': 0.616822429906542,\n",
       "     'f1-score': 0.609404401837762,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.6, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5333333333333333,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5161290322580646,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.3703703703703704,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.6085185185185185,\n",
       "     'recall': 0.635119940029985,\n",
       "     'f1-score': 0.6195415173237755,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5905019037729318,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.5968710570685247,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.8, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5517241379310345,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5245901639344263,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.38461538461538464,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.3636363636363637,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7659574468085107,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.6090848806366047,\n",
       "     'recall': 0.6351199400299851,\n",
       "     'f1-score': 0.6194283465360017,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5916730707256005,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.5971078274629923,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=1.0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4482758620689655,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7037037037037037,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.76,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.616822429906542,\n",
       "    'macro avg': {'precision': 0.6134259259259259,\n",
       "     'recall': 0.6484140742128935,\n",
       "     'f1-score': 0.6261331366402361,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5975250951886466,\n",
       "     'recall': 0.616822429906542,\n",
       "     'f1-score': 0.6025709809895892,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.41379310344827586,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.598956043956044,\n",
       "     'recall': 0.6297320089955023,\n",
       "     'f1-score': 0.6108657165225436,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5798459484440793,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5856133266950622,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.41379310344827586,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.598956043956044,\n",
       "     'recall': 0.6297320089955023,\n",
       "     'f1-score': 0.6108657165225436,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5798459484440793,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5856133266950622,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7777777777777778,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.84,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.4067796610169491,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4285714285714286,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.5897435897435898,\n",
       "     'recall': 0.6211113193403298,\n",
       "     'f1-score': 0.6025112417848495,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5693745506829618,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5762942034092268,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.44,\n",
       "     'recall': 0.34375,\n",
       "     'f1-score': 0.3859649122807018,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.5866483516483516,\n",
       "     'recall': 0.6219195089955023,\n",
       "     'f1-score': 0.6000821381184052,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5674519872650714,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5740007759129229,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7241379310344828,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8076923076923076,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.3125,\n",
       "     'f1-score': 0.35714285714285715,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.574349501073639,\n",
       "     'recall': 0.6141070089955023,\n",
       "     'f1-score': 0.5889173483158445,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5549146577989634,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.561976858547725,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.41379310344827586,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.48148148148148145,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4642857142857143,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.5963319088319088,\n",
       "     'recall': 0.6297320089955023,\n",
       "     'f1-score': 0.609075526762429,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5785539313576696,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5845308474662827,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.41379310344827586,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.43636363636363634,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.72,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.5849358974358975,\n",
       "     'recall': 0.6211113193403298,\n",
       "     'f1-score': 0.5984215378941544,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5676371914689672,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5738046844437245,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.44,\n",
       "     'recall': 0.34375,\n",
       "     'f1-score': 0.3859649122807018,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4285714285714286,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.72,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5752777777777778,\n",
       "     'recall': 0.6132988193403298,\n",
       "     'f1-score': 0.5895164381542091,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5565628245067497,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.563370327963945,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.44,\n",
       "     'recall': 0.34375,\n",
       "     'f1-score': 0.3859649122807018,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.5866483516483516,\n",
       "     'recall': 0.6219195089955023,\n",
       "     'f1-score': 0.6000821381184052,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5674519872650714,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5740007759129229,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.44,\n",
       "     'recall': 0.34375,\n",
       "     'f1-score': 0.3859649122807018,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4285714285714286,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.72,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5752777777777778,\n",
       "     'recall': 0.6132988193403298,\n",
       "     'f1-score': 0.5895164381542091,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5565628245067497,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.563370327963945,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.44,\n",
       "     'recall': 0.34375,\n",
       "     'f1-score': 0.3859649122807018,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4285714285714286,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.72,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5752777777777778,\n",
       "     'recall': 0.6132988193403298,\n",
       "     'f1-score': 0.5895164381542091,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5565628245067497,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.563370327963945,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7586206896551724,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8461538461538461,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5405405405405406,\n",
       "     'recall': 0.625,\n",
       "     'f1-score': 0.5797101449275363,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.40816326530612246,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7619047619047619,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7272727272727272,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6402664980251187,\n",
       "     'recall': 0.6555003748125937,\n",
       "     'f1-score': 0.640324995915058,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6240129222726708,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6222081357043916,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.84,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8749999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4838709677419355,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.48148148148148145,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4642857142857143,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6453703703703704,\n",
       "     'recall': 0.6640390742128935,\n",
       "     'f1-score': 0.6537058371735791,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6239529248875043,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6287989721061774,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.8333333333333334,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.851063829787234,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.41379310344827586,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4827586206896552,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.4827586206896552,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7142857142857143,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7843137254901961,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.616822429906542,\n",
       "    'macro avg': {'precision': 0.6229790324617911,\n",
       "     'recall': 0.6492222638680659,\n",
       "     'f1-score': 0.6329823198538403,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6015370921912979,\n",
       "     'recall': 0.616822429906542,\n",
       "     'f1-score': 0.6061220848759413,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.8333333333333334,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.851063829787234,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.44,\n",
       "     'recall': 0.34375,\n",
       "     'f1-score': 0.3859649122807018,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4482758620689655,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6551724137931034,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7307692307692308,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.5941954022988506,\n",
       "     'recall': 0.6219195089955022,\n",
       "     'f1-score': 0.604018458726533,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5730432914383929,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5769442765026276,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None}],\n",
       " 'RepeatedKFold': [{'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7586206896551724,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8461538461538461,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.6285714285714286,\n",
       "     'recall': 0.6875,\n",
       "     'f1-score': 0.6567164179104478,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5833333333333334,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.5283018867924529,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8947368421052632,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.8095238095238095,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.7009345794392523,\n",
       "    'macro avg': {'precision': 0.7163155734162994,\n",
       "     'recall': 0.7164776986506747,\n",
       "     'f1-score': 0.7101739900951392,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.7014782767424524,\n",
       "     'recall': 0.7009345794392523,\n",
       "     'f1-score': 0.6954791230906685,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8333333333333334,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.851063829787234,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.53125,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.53125,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.782608695652174,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.782608695652174,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6528694358178054,\n",
       "     'recall': 0.657924943778111,\n",
       "     'f1-score': 0.6552657190791502,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6320649755229194,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6336685818742521,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5357142857142857,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.5,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.43333333333333335,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.44067796610169496,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7083333333333334,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.723404255319149,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6093452380952381,\n",
       "     'recall': 0.6205608133433284,\n",
       "     'f1-score': 0.6139372220218776,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5932821539830886,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5946382450712423,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.4666666666666667,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6538461538461539,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.693877551020408,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.604532967032967,\n",
       "     'recall': 0.6236178785607196,\n",
       "     'f1-score': 0.6125044754744002,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5878761425490399,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5914696621393268,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5555555555555556,\n",
       "     'recall': 0.625,\n",
       "     'f1-score': 0.5882352941176471,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5416666666666666,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.49056603773584906,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8421052631578947,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.761904761904762,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6542056074766355,\n",
       "    'macro avg': {'precision': 0.6723318713450293,\n",
       "     'recall': 0.6704928785607196,\n",
       "     'f1-score': 0.6660588763807409,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6551825435863803,\n",
       "     'recall': 0.6542056074766355,\n",
       "     'f1-score': 0.6496722476682438,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8333333333333334,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.851063829787234,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5161290322580645,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5079365079365079,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4666666666666667,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.47457627118644075,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8636363636363636,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8444444444444444,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6448598130841121,\n",
       "    'macro avg': {'precision': 0.6699413489736071,\n",
       "     'recall': 0.6696026986506747,\n",
       "     'f1-score': 0.6695052633386568,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6456052840737797,\n",
       "     'recall': 0.6448598130841121,\n",
       "     'f1-score': 0.6449847703336788,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial', solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.9090909090909091,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.888888888888889,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5357142857142857,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.5,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4375,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.4590163934426229,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.68,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7083333333333334,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.616822429906542,\n",
       "    'macro avg': {'precision': 0.6405762987012987,\n",
       "     'recall': 0.640051068215892,\n",
       "     'f1-score': 0.6390596539162113,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6203686733826922,\n",
       "     'recall': 0.616822429906542,\n",
       "     'f1-score': 0.6172671637471698,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4827586206896552,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.4590163934426229,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.48148148148148145,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4642857142857143,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7037037037037037,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.76,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.6149026181353767,\n",
       "     'recall': 0.634487443778111,\n",
       "     'f1-score': 0.6229531865065525,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5963061433976677,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.6002668690215021,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.5652173913043478,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.5652173913043478,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.38461538461538464,\n",
       "     'recall': 0.625,\n",
       "     'f1-score': 0.4761904761904762,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3076923076923077,\n",
       "     'recall': 0.13793103448275862,\n",
       "     'f1-score': 0.1904761904761905,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6842105263157895,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.6190476190476191,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.4672897196261682,\n",
       "    'macro avg': {'precision': 0.4854339024819574,\n",
       "     'recall': 0.47334145427286356,\n",
       "     'f1-score': 0.46273291925465837,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.46698702183207835,\n",
       "     'recall': 0.4672897196261682,\n",
       "     'f1-score': 0.4485981308411215,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8076923076923077,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8571428571428572,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4838709677419355,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.32142857142857145,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.31578947368421056,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7391304347826086,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7391304347826085,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.592062828475872,\n",
       "     'recall': 0.6078171851574212,\n",
       "     'f1-score': 0.5989834333379029,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5691434733490809,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5734210412978482,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial', penalty='l1',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5769230769230769,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.5172413793103449,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5333333333333333,\n",
       "     'recall': 0.5517241379310345,\n",
       "     'f1-score': 0.5423728813559322,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7083333333333334,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.723404255319149,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6398326210826211,\n",
       "     'recall': 0.6572924475262368,\n",
       "     'f1-score': 0.6457546289963565,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6285692414197087,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6291479959775094,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7241379310344828,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8076923076923076,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4838709677419355,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.6521739130434783,\n",
       "     'f1-score': 0.6976744186046512,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6096059113300493,\n",
       "     'recall': 0.6205608133433284,\n",
       "     'f1-score': 0.6113445112290218,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5922379264306432,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5919194004486971,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7096774193548387,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8148148148148149,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.6060606060606061,\n",
       "     'recall': 0.625,\n",
       "     'f1-score': 0.6153846153846154,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.625,\n",
       "     'recall': 0.5172413793103449,\n",
       "     'f1-score': 0.5660377358490567,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7894736842105263,\n",
       "     'recall': 0.6521739130434783,\n",
       "     'f1-score': 0.7142857142857143,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6728971962616822,\n",
       "    'macro avg': {'precision': 0.6825529274064928,\n",
       "     'recall': 0.6877342578710646,\n",
       "     'f1-score': 0.6776307200835503,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.67289172687797,\n",
       "     'recall': 0.6728971962616822,\n",
       "     'f1-score': 0.6661375158994627,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.84,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8749999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5517241379310345,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5245901639344263,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.49122807017543857,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6448598130841121,\n",
       "    'macro avg': {'precision': 0.6529310344827586,\n",
       "     'recall': 0.6696026986506747,\n",
       "     'f1-score': 0.6602045585274662,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6358427328391879,\n",
       "     'recall': 0.6448598130841121,\n",
       "     'f1-score': 0.6393224231868164,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4117647058823529,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.42424242424242425,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.42857142857142855,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.36000000000000004,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5607476635514018,\n",
       "    'macro avg': {'precision': 0.5658532643826761,\n",
       "     'recall': 0.58913511994003,\n",
       "     'f1-score': 0.5736116264687694,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5451944976408967,\n",
       "     'recall': 0.5607476635514018,\n",
       "     'f1-score': 0.5490696397505476,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4,\n",
       "     'recall': 0.3125,\n",
       "     'f1-score': 0.3508771929824561,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4067796610169491,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7037037037037037,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.76,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5700934579439252,\n",
       "    'macro avg': {'precision': 0.575925925925926,\n",
       "     'recall': 0.6054863193403298,\n",
       "     'f1-score': 0.5877475468331846,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.551263412945656,\n",
       "     'recall': 0.5700934579439252,\n",
       "     'f1-score': 0.557676140295297,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7857142857142857,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8627450980392156,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.525,\n",
       "     'recall': 0.65625,\n",
       "     'f1-score': 0.5833333333333334,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5263157894736842,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.4166666666666667,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.6521739130434783,\n",
       "     'f1-score': 0.6976744186046512,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6467575187969925,\n",
       "     'recall': 0.6524433095952025,\n",
       "     'f1-score': 0.6401048791609667,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6297624903379946,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6228004568486817,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7333333333333333,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8301886792452831,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5384615384615384,\n",
       "     'recall': 0.65625,\n",
       "     'f1-score': 0.5915492957746479,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.45,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.3673469387755102,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8888888888888888,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7804878048780488,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6526709401709401,\n",
       "     'recall': 0.6546921851574212,\n",
       "     'f1-score': 0.6423931796683724,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6316998162792555,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6226934376085529,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.7924528301886793,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.48717948717948717,\n",
       "     'recall': 0.59375,\n",
       "     'f1-score': 0.5352112676056338,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.43478260869565216,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.38461538461538464,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8666666666666667,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.6842105263157895,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.6221571906354515,\n",
       "     'recall': 0.6042096139430285,\n",
       "     'f1-score': 0.5991225021813718,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6002969399556153,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5817183543628899,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.7924528301886793,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.5625,\n",
       "     'f1-score': 0.5070422535211268,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.45,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.3673469387755102,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8333333333333334,\n",
       "     'recall': 0.6521739130434783,\n",
       "     'f1-score': 0.7317073170731708,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.6112179487179487,\n",
       "     'recall': 0.6095155547226387,\n",
       "     'f1-score': 0.5996373348896218,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5895878265037143,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5788233338709197,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.6363636363636364,\n",
       "     'recall': 0.6086956521739131,\n",
       "     'f1-score': 0.6222222222222223,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.41304347826086957,\n",
       "     'recall': 0.59375,\n",
       "     'f1-score': 0.4871794871794871,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.30434782608695654,\n",
       "     'recall': 0.2413793103448276,\n",
       "     'f1-score': 0.2692307692307692,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8125,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.6666666666666667,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.4953271028037383,\n",
       "    'macro avg': {'precision': 0.5415637351778656,\n",
       "     'recall': 0.5022605884557722,\n",
       "     'f1-score': 0.5113247863247863,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.517451793432086,\n",
       "     'recall': 0.4953271028037383,\n",
       "     'f1-score': 0.4957185078680406,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.6818181818181818,\n",
       "     'recall': 0.6521739130434783,\n",
       "     'f1-score': 0.6666666666666666,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.6875,\n",
       "     'f1-score': 0.5238095238095238,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.26666666666666666,\n",
       "     'recall': 0.13793103448275862,\n",
       "     'f1-score': 0.18181818181818182,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7222222222222222,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.6341463414634146,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5046728971962616,\n",
       "    'macro avg': {'precision': 0.5234459984459984,\n",
       "     'recall': 0.5107055847076462,\n",
       "     'f1-score': 0.5016101784394468,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5006048987357399,\n",
       "     'recall': 0.5046728971962616,\n",
       "     'f1-score': 0.4855451516039617,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8695652173913043,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8695652173913043,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4666666666666667,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.45161290322580644,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.39285714285714285,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.3859649122807017,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6149645644210862,\n",
       "     'recall': 0.6281156296851574,\n",
       "     'f1-score': 0.6206633092448612,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5900362876998391,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.59328345844153,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.875,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8936170212765957,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5714285714285714,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5333333333333333,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5172413793103449,\n",
       "     'recall': 0.5172413793103449,\n",
       "     'f1-score': 0.5172413793103449,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6635514018691588,\n",
       "    'macro avg': {'precision': 0.6736097953770368,\n",
       "     'recall': 0.6890929535232384,\n",
       "     'f1-score': 0.6799254845004766,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6562467905925851,\n",
       "     'recall': 0.6635514018691588,\n",
       "     'f1-score': 0.6584728303729525,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.2, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.88,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.9166666666666666,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.6129032258064516,\n",
       "     'recall': 0.59375,\n",
       "     'f1-score': 0.6031746031746031,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4444444444444444,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4285714285714286,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7659574468085107,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6635514018691588,\n",
       "    'macro avg': {'precision': 0.671836917562724,\n",
       "     'recall': 0.6866683845577212,\n",
       "     'f1-score': 0.6785925363053023,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6541288982681807,\n",
       "     'recall': 0.6635514018691588,\n",
       "     'f1-score': 0.6582290966363347,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.4, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7096774193548387,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8148148148148149,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5185185185185185,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.47457627118644063,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7727272727272727,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7555555555555555,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6020826545020093,\n",
       "     'recall': 0.6281156296851573,\n",
       "     'f1-score': 0.6094509461034885,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5841375264046352,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.58596090036768,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.6, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.875,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8936170212765957,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4857142857142857,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.5074626865671641,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3333333333333333,\n",
       "     'recall': 0.27586206896551724,\n",
       "     'f1-score': 0.3018867924528302,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7659574468085107,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6110119047619047,\n",
       "     'recall': 0.6256910607196402,\n",
       "     'f1-score': 0.6172309867762752,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5849020916777926,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.590315287076998,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.8, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7777777777777778,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.84,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5357142857142857,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.5,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.39285714285714285,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.3859649122807017,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7083333333333334,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.723404255319149,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6036706349206349,\n",
       "     'recall': 0.6250585644677662,\n",
       "     'f1-score': 0.6123422918999626,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.586133363002522,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5901988815745868,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=1.0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.6774193548387096,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.7777777777777777,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.52,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.45614035087719296,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.68,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7083333333333334,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.5943548387096774,\n",
       "     'recall': 0.626674943778111,\n",
       "     'f1-score': 0.6037446836788942,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5828097678625264,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.583982595259034,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4482758620689655,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7727272727272727,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7555555555555555,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.6281674503657262,\n",
       "     'recall': 0.6283733133433284,\n",
       "     'f1-score': 0.6280855139805983,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.607299631832342,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.6072291818563443,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.48148148148148145,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4406779661016949,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5384615384615384,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.509090909090909,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6666666666666666,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7547169811320754,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.616822429906542,\n",
       "    'macro avg': {'precision': 0.6195690883190883,\n",
       "     'recall': 0.6461651986506747,\n",
       "     'f1-score': 0.6282491236556379,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6034061559762495,\n",
       "     'recall': 0.616822429906542,\n",
       "     'f1-score': 0.6057903413624243,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.8260869565217391,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8260869565217391,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5172413793103449,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4918032786885246,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.41935483870967744,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4333333333333333,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7659574468085107,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.6281707936354404,\n",
       "     'recall': 0.6314303785607197,\n",
       "     'f1-score': 0.629295253838027,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6071309762664644,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.6067419893578991,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.84,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8749999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5925925925925926,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5423728813559322,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5333333333333333,\n",
       "     'recall': 0.5517241379310345,\n",
       "     'f1-score': 0.5423728813559322,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6635514018691588,\n",
       "    'macro avg': {'precision': 0.6714814814814813,\n",
       "     'recall': 0.6868440779610195,\n",
       "     'f1-score': 0.677436440677966,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6570993423329872,\n",
       "     'recall': 0.6635514018691588,\n",
       "     'f1-score': 0.6585022968477744,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.48,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.42105263157894735,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.5517241379310345,\n",
       "     'f1-score': 0.5245901639344263,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.616822429906542,\n",
       "    'macro avg': {'precision': 0.625,\n",
       "     'recall': 0.6447245127436282,\n",
       "     'f1-score': 0.6322440322116767,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6057943925233645,\n",
       "     'recall': 0.616822429906542,\n",
       "     'f1-score': 0.6084436040307603,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.32142857142857145,\n",
       "     'recall': 0.28125,\n",
       "     'f1-score': 0.30000000000000004,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4067796610169491,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7083333333333334,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.723404255319149,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5233644859813084,\n",
       "    'macro avg': {'precision': 0.5374404761904762,\n",
       "     'recall': 0.5541955584707645,\n",
       "     'f1-score': 0.5450459790840245,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5115643079661772,\n",
       "     'recall': 0.5233644859813084,\n",
       "     'f1-score': 0.5166813835685229,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.34375,\n",
       "     'f1-score': 0.37288135593220334,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.45161290322580644,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.4666666666666667,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7391304347826086,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7391304347826085,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.591845378661648,\n",
       "     'recall': 0.608801068215892,\n",
       "     'f1-score': 0.5987512469984309,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5684684011485338,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5723462329649108,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4333333333333333,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7142857142857143,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7843137254901961,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.5904120879120879,\n",
       "     'recall': 0.6203031296851574,\n",
       "     'f1-score': 0.602328431372549,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5704200472424772,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5767683708997619,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4838709677419355,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.43636363636363634,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6034615384615385,\n",
       "     'recall': 0.6228096889055472,\n",
       "     'f1-score': 0.6116487870808147,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5868008626887132,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.591072046161628,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5151515151515151,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.5230769230769231,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.43478260869565216,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.38461538461538464,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.64,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.6666666666666666,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5801758386540995,\n",
       "     'recall': 0.5994541791604198,\n",
       "     'f1-score': 0.5874672946101517,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5665536116328477,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5706764085936314,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5161290322580645,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5079365079365079,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5185185185185185,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.5,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6261682242990654,\n",
       "    'macro avg': {'precision': 0.6365785543608125,\n",
       "     'recall': 0.6478635682158921,\n",
       "     'f1-score': 0.6416117865585951,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6198270972208265,\n",
       "     'recall': 0.6261682242990654,\n",
       "     'f1-score': 0.6224272236899002,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5428571428571428,\n",
       "     'recall': 0.59375,\n",
       "     'f1-score': 0.5671641791044776,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5416666666666666,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.49056603773584906,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7441860465116279,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6448598130841121,\n",
       "    'macro avg': {'precision': 0.6586309523809524,\n",
       "     'recall': 0.6626803785607196,\n",
       "     'f1-score': 0.6563614187791651,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6423342234089897,\n",
       "     'recall': 0.6448598130841121,\n",
       "     'f1-score': 0.6395619099629772,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4074074074074074,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.39285714285714285,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6062285096767857,\n",
       "     'recall': 0.6311726949025487,\n",
       "     'f1-score': 0.6171866287498606,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5817939261058823,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5885455913635563,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.41379310344827586,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.3934426229508197,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.45161290322580644,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.4666666666666667,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8260869565217391,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8260869565217391,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.620789907465622,\n",
       "     'recall': 0.6274831334332834,\n",
       "     'f1-score': 0.6236767211092745,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5938924003479117,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5955069340991648,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4838709677419355,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.47619047619047616,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.43636363636363634,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7659574468085107,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.606544665012407,\n",
       "     'recall': 0.6228096889055472,\n",
       "     'f1-score': 0.613505440861064,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5880951276640153,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5920223987206915,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None}],\n",
       " 'RepeatedStratifiedKFold': [{'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5588235294117647,\n",
       "     'recall': 0.59375,\n",
       "     'f1-score': 0.5757575757575757,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5416666666666666,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.49056603773584906,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7619047619047619,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7272727272727272,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6448598130841121,\n",
       "    'macro avg': {'precision': 0.6530987394957983,\n",
       "     'recall': 0.6626803785607196,\n",
       "     'f1-score': 0.6542814381327143,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6389205214796199,\n",
       "     'recall': 0.6448598130841121,\n",
       "     'f1-score': 0.6384963244527383,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8076923076923077,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8571428571428572,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5666666666666667,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.5483870967741935,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.48,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4444444444444445,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6542056074766355,\n",
       "    'macro avg': {'precision': 0.6558974358974359,\n",
       "     'recall': 0.6819129497751124,\n",
       "     'f1-score': 0.6665752322434351,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6385286364725616,\n",
       "     'recall': 0.6542056074766355,\n",
       "     'f1-score': 0.6441782420937424,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5714285714285714,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5333333333333333,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6357346357346357,\n",
       "     'recall': 0.6609820089955022,\n",
       "     'f1-score': 0.6453927025355597,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6227144264527441,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6262849744825714,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4333333333333333,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.48148148148148145,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4642857142857143,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.5922110297110297,\n",
       "     'recall': 0.6158053785607197,\n",
       "     'f1-score': 0.6019557823129251,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5752418229053743,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5800527687710597,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7096774193548387,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8148148148148149,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5833333333333334,\n",
       "     'recall': 0.65625,\n",
       "     'f1-score': 0.6176470588235293,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5263157894736842,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.4166666666666667,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7619047619047619,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7272727272727272,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6448598130841121,\n",
       "    'macro avg': {'precision': 0.6453078260166545,\n",
       "     'recall': 0.6633128748125937,\n",
       "     'f1-score': 0.6441003168944346,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6334225675735918,\n",
       "     'recall': 0.6448598130841121,\n",
       "     'f1-score': 0.6291219876981284,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5862068965517241,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.5573770491803278,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.48148148148148145,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4642857142857143,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6399990175852244,\n",
       "     'recall': 0.657924943778111,\n",
       "     'f1-score': 0.647422493587599,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6265856128569632,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6295792255924891,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial', solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8235294117647057,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5185185185185185,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.47457627118644063,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6344373219373219,\n",
       "     'recall': 0.6670961394302849,\n",
       "     'f1-score': 0.646789871572666,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6171486007934607,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6225440959039895,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.43333333333333335,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.41935483870967744,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.375,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.339622641509434,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5700934579439252,\n",
       "    'macro avg': {'precision': 0.5699608262108262,\n",
       "     'recall': 0.6030617503748126,\n",
       "     'f1-score': 0.583621921075186,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.547536411321458,\n",
       "     'recall': 0.5700934579439252,\n",
       "     'f1-score': 0.5561228610874842,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='sag'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.64,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.6666666666666666,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4883720930232558,\n",
       "     'recall': 0.65625,\n",
       "     'f1-score': 0.5599999999999999,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.45,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.3673469387755102,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6842105263157895,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.6190476190476191,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5514018691588785,\n",
       "    'macro avg': {'precision': 0.5656456548347614,\n",
       "     'recall': 0.5568660982008995,\n",
       "     'f1-score': 0.553265306122449,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5526612063739004,\n",
       "     'recall': 0.5514018691588785,\n",
       "     'f1-score': 0.5434064466908258,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.6896551724137931,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7692307692307693,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5714285714285714,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5333333333333333,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4583333333333333,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4150943396226415,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.6029311923708476,\n",
       "     'recall': 0.6328710644677661,\n",
       "     'f1-score': 0.6130880799344411,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5921731480464965,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.5952772840346208,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial', penalty='l1',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4827586206896552,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.4590163934426229,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.48148148148148145,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4642857142857143,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.616822429906542,\n",
       "    'macro avg': {'precision': 0.6237523332350918,\n",
       "     'recall': 0.6453570089955022,\n",
       "     'f1-score': 0.6330364112858258,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6039152442310677,\n",
       "     'recall': 0.616822429906542,\n",
       "     'f1-score': 0.608936557616765,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l1',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4482758620689655,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4482758620689655,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.616822429906542,\n",
       "    'macro avg': {'precision': 0.621684350132626,\n",
       "     'recall': 0.6484140742128935,\n",
       "     'f1-score': 0.6323011963406052,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.601725377426312,\n",
       "     'recall': 0.616822429906542,\n",
       "     'f1-score': 0.6065032522838334,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7096774193548387,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8148148148148149,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5142857142857142,\n",
       "     'recall': 0.5625,\n",
       "     'f1-score': 0.5373134328358209,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.55,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4489795918367347,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7619047619047619,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.7272727272727272,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6261682242990654,\n",
       "    'macro avg': {'precision': 0.6339669738863287,\n",
       "     'recall': 0.6484960644677661,\n",
       "     'f1-score': 0.6320951416900245,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6191918974403147,\n",
       "     'recall': 0.6261682242990654,\n",
       "     'f1-score': 0.6138546867478976,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7777777777777778,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.84,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.375,\n",
       "     'f1-score': 0.41379310344827586,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.43333333333333335,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.44067796610169496,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.6160790598290599,\n",
       "     'recall': 0.6406015742128935,\n",
       "     'f1-score': 0.6257454269619608,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5928328940011183,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.597540046805094,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4262295081967213,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4827586206896552,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.4827586206896552,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7083333333333334,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.723404255319149,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.5998419540229886,\n",
       "     'recall': 0.6135565029985008,\n",
       "     'f1-score': 0.6060147627180481,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5805279836717155,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5839810791398957,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.45161290322580644,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.4444444444444444,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.37735849056603776,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.68,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7083333333333334,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5700934579439252,\n",
       "    'macro avg': {'precision': 0.5722550776583035,\n",
       "     'recall': 0.5977558095952024,\n",
       "     'f1-score': 0.5825340670859539,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5533830212485624,\n",
       "     'recall': 0.5700934579439252,\n",
       "     'f1-score': 0.5594138795822802,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7333333333333333,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8301886792452831,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5757575757575758,\n",
       "     'recall': 0.59375,\n",
       "     'f1-score': 0.5846153846153846,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5238095238095238,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.44,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.782608695652174,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.782608695652174,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6542056074766355,\n",
       "    'macro avg': {'precision': 0.6538772821381517,\n",
       "     'recall': 0.6780476949025487,\n",
       "     'f1-score': 0.6593531898782103,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6400129465550026,\n",
       "     'recall': 0.6542056074766355,\n",
       "     'f1-score': 0.6407666535545217,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7096774193548387,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8148148148148149,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5365853658536586,\n",
       "     'recall': 0.6875,\n",
       "     'f1-score': 0.6027397260273972,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5555555555555556,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.4255319148936171,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8823529411764706,\n",
       "     'recall': 0.6521739130434783,\n",
       "     'f1-score': 0.75,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6448598130841121,\n",
       "    'macro avg': {'precision': 0.6710428204851309,\n",
       "     'recall': 0.6602558095952025,\n",
       "     'f1-score': 0.6482716139339573,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6532573935574608,\n",
       "     'recall': 0.6448598130841121,\n",
       "     'f1-score': 0.6319517523881528,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7333333333333333,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8301886792452831,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5588235294117647,\n",
       "     'recall': 0.59375,\n",
       "     'f1-score': 0.5757575757575757,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.43636363636363634,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8823529411764706,\n",
       "     'recall': 0.6521739130434783,\n",
       "     'f1-score': 0.75,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6590120663650075,\n",
       "     'recall': 0.6540596889055472,\n",
       "     'f1-score': 0.6480774728416238,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6395117069113772,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6301226869292467,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7407407407407407,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7999999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4878048780487805,\n",
       "     'recall': 0.625,\n",
       "     'f1-score': 0.547945205479452,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3157894736842105,\n",
       "     'recall': 0.20689655172413793,\n",
       "     'f1-score': 0.25,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.6521739130434783,\n",
       "     'f1-score': 0.6976744186046512,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5700934579439252,\n",
       "    'macro avg': {'precision': 0.5735837731184329,\n",
       "     'recall': 0.58840892053973,\n",
       "     'f1-score': 0.5739049060210257,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5519129707611226,\n",
       "     'recall': 0.5700934579439252,\n",
       "     'f1-score': 0.5535584878808358,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.75,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7659574468085107,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5106382978723404,\n",
       "     'recall': 0.75,\n",
       "     'f1-score': 0.6075949367088608,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.42105263157894735,\n",
       "     'recall': 0.27586206896551724,\n",
       "     'f1-score': 0.3333333333333333,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7647058823529411,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.65,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.6115992029510572,\n",
       "     'recall': 0.5934220389805097,\n",
       "     'f1-score': 0.5892214292126762,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5924223097366542,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5764179992331399,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7368421052631579,\n",
       "     'recall': 0.6086956521739131,\n",
       "     'f1-score': 0.6666666666666666,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4339622641509434,\n",
       "     'recall': 0.71875,\n",
       "     'f1-score': 0.5411764705882353,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3125,\n",
       "     'recall': 0.1724137931034483,\n",
       "     'f1-score': 0.22222222222222224,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.631578947368421,\n",
       "     'recall': 0.5217391304347826,\n",
       "     'f1-score': 0.5714285714285715,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5046728971962616,\n",
       "    'macro avg': {'precision': 0.5287208291956306,\n",
       "     'recall': 0.505399643928036,\n",
       "     'f1-score': 0.5003734827264239,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5086259501248271,\n",
       "     'recall': 0.5046728971962616,\n",
       "     'f1-score': 0.4882082427986771,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7777777777777778,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.84,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5172413793103449,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4918032786885246,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.48,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4444444444444445,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6261682242990654,\n",
       "    'macro avg': {'precision': 0.6264470969643383,\n",
       "     'recall': 0.6554183845577212,\n",
       "     'f1-score': 0.6379394818036503,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.609049582565535,\n",
       "     'recall': 0.6261682242990654,\n",
       "     'f1-score': 0.6147974626242917,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.44,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4074074074074074,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7083333333333334,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.723404255319149,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6043910256410256,\n",
       "     'recall': 0.6220014992503748,\n",
       "     'f1-score': 0.6117845483347003,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5863922837287323,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5909217092638961,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.2, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8076923076923077,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8571428571428572,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5277777777777778,\n",
       "     'recall': 0.59375,\n",
       "     'f1-score': 0.5588235294117648,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.36,\n",
       "     'recall': 0.3103448275862069,\n",
       "     'f1-score': 0.3333333333333333,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.6521739130434783,\n",
       "     'f1-score': 0.6976744186046512,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6113675213675214,\n",
       "     'recall': 0.6173280547226387,\n",
       "     'f1-score': 0.6117435346231517,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5902412333253455,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5916805322433255,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.4, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8148148148148148,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8800000000000001,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5161290322580645,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5079365079365079,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.43478260869565216,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.38461538461538464,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6261682242990654,\n",
       "    'macro avg': {'precision': 0.6241239216344405,\n",
       "     'recall': 0.6568590704647677,\n",
       "     'f1-score': 0.6370155241583813,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6044229694660282,\n",
       "     'recall': 0.6261682242990654,\n",
       "     'f1-score': 0.6120051317915136,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.6, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7857142857142857,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8627450980392156,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5517241379310345,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5245901639344263,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7659574468085107,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6261682242990654,\n",
       "    'macro avg': {'precision': 0.6276288366805609,\n",
       "     'recall': 0.6546101949025487,\n",
       "     'f1-score': 0.6383231771955382,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6097741285462844,\n",
       "     'recall': 0.6261682242990654,\n",
       "     'f1-score': 0.6153929324990594,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=0.8, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.7777777777777778,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.84,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5161290322580645,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5079365079365079,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4230769230769231,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7391304347826086,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7391304347826085,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.6140285419738435,\n",
       "     'recall': 0.6328710644677662,\n",
       "     'f1-score': 0.621766735679779,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5950864363586702,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.599756712653909,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, l1_ratio=1.0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5357142857142857,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.5,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5384615384615384,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.509090909090909,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7037037037037037,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.76,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6367775742775743,\n",
       "     'recall': 0.6617901986506747,\n",
       "     'f1-score': 0.6463543599257885,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6227638751003237,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6263471641842804,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.45161290322580644,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.4444444444444444,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4166666666666667,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.37735849056603776,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5700934579439252,\n",
       "    'macro avg': {'precision': 0.5728391232423491,\n",
       "     'recall': 0.5977558095952025,\n",
       "     'f1-score': 0.5830017541607838,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5538851912834428,\n",
       "     'recall': 0.5700934579439252,\n",
       "     'f1-score': 0.5598160030484892,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.8260869565217391,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8260869565217391,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.59375,\n",
       "     'recall': 0.59375,\n",
       "     'f1-score': 0.59375,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5384615384615384,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.509090909090909,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6728971962616822,\n",
       "    'macro avg': {'precision': 0.6818823160535117,\n",
       "     'recall': 0.6930401986506747,\n",
       "     'f1-score': 0.6863135990562232,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6664270309130123,\n",
       "     'recall': 0.6728971962616822,\n",
       "     'f1-score': 0.668590154838486,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.8260869565217391,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8260869565217391,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.46875,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.46875,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.38461538461538464,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.3636363636363637,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.6025553929765887,\n",
       "     'recall': 0.6164378748125937,\n",
       "     'f1-score': 0.6084958810599339,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5790797987059669,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5830111143862813,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.72,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7499999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.48148148148148145,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4406779661016949,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.49122807017543857,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6296296296296297,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.68,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5827777777777777,\n",
       "     'recall': 0.6026869377811095,\n",
       "     'f1-score': 0.5904765090692834,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5696157840083074,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5723112986013267,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.782608695652174,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.782608695652174,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5172413793103449,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4918032786885246,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3939393939393939,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.41935483870967744,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7272727272727273,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.711111111111111,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.60526554904366,\n",
       "     'recall': 0.5988216829085458,\n",
       "     'f1-score': 0.6012194810403717,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5860115821443568,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5818182317398971,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5517241379310345,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5245901639344263,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6923076923076923,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7346938775510203,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6261682242990654,\n",
       "    'macro avg': {'precision': 0.6283156498673741,\n",
       "     'recall': 0.650112443778111,\n",
       "     'f1-score': 0.6370844612062411,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6146781030764273,\n",
       "     'recall': 0.6261682242990654,\n",
       "     'f1-score': 0.6184060331097911,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   'l1_ratio': 0},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4666666666666667,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.45161290322580644,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.41379310344827586,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.41379310344827586,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7391304347826086,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7391304347826085,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5794392523364486,\n",
       "    'macro avg': {'precision': 0.5948975512243877,\n",
       "     'recall': 0.6041276236881559,\n",
       "     'f1-score': 0.5990507770308394,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5739563862928349,\n",
       "     'recall': 0.5794392523364486,\n",
       "     'f1-score': 0.5762611797809265,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.2, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.2},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.4666666666666667,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.45161290322580644,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7083333333333334,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.723404255319149,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5887850467289719,\n",
       "    'macro avg': {'precision': 0.5998214285714286,\n",
       "     'recall': 0.6127483133433284,\n",
       "     'f1-score': 0.6057060440222038,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5810213618157544,\n",
       "     'recall': 0.5887850467289719,\n",
       "     'f1-score': 0.5843580774237213,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.4},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.41935483870967744,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4126984126984127,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4,\n",
       "     'recall': 0.3448275862068966,\n",
       "     'f1-score': 0.3703703703703704,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7037037037037037,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.76,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5700934579439252,\n",
       "    'macro avg': {'precision': 0.5786813022700119,\n",
       "     'recall': 0.6008128748125937,\n",
       "     'f1-score': 0.5878948553416639,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.555260498665684,\n",
       "     'recall': 0.5700934579439252,\n",
       "     'f1-score': 0.5609610712891683,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.6, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.6},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7142857142857143,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.7843137254901961,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4482758620689655,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4666666666666667,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.47457627118644075,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7391304347826086,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.7391304347826085,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6050207039337474,\n",
       "     'recall': 0.624426068215892,\n",
       "     'f1-score': 0.6115740733820527,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5884290164663997,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.5901565900643756,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=0.8, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 0.8},\n",
       "  {'penalty': 'elasticnet',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.6551724137931034,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7307692307692308,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.4666666666666667,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.75,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.7659574468085107,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6012931034482758,\n",
       "     'recall': 0.6236178785607197,\n",
       "     'f1-score': 0.6090301542429203,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5870931356751531,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.589412503053386,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   'l1_ratio': 1.0},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 0.1,\n",
       "   'report': {'Category 1': {'precision': 0.7857142857142857,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8627450980392156,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5405405405405406,\n",
       "     'recall': 0.625,\n",
       "     'f1-score': 0.5797101449275363,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.55,\n",
       "     'recall': 0.3793103448275862,\n",
       "     'f1-score': 0.4489795918367347,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7272727272727273,\n",
       "     'recall': 0.6956521739130435,\n",
       "     'f1-score': 0.711111111111111,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6448598130841121,\n",
       "    'macro avg': {'precision': 0.6508818883818884,\n",
       "     'recall': 0.6641210644677661,\n",
       "     'f1-score': 0.6506364864786494,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6359439121121364,\n",
       "     'recall': 0.6448598130841121,\n",
       "     'f1-score': 0.6333628561813456,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 1,\n",
       "   'report': {'Category 1': {'precision': 0.8333333333333334,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.851063829787234,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5806451612903226,\n",
       "     'recall': 0.5625,\n",
       "     'f1-score': 0.5714285714285715,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6542056074766355,\n",
       "    'macro avg': {'precision': 0.6674827188940092,\n",
       "     'recall': 0.6766070089955022,\n",
       "     'f1-score': 0.6717858475977178,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6487844007063182,\n",
       "     'recall': 0.6542056074766355,\n",
       "     'f1-score': 0.6512523105337413,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 10,\n",
       "   'report': {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.40625,\n",
       "     'f1-score': 0.4482758620689655,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.42424242424242425,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.45161290322580644,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6074766355140186,\n",
       "    'macro avg': {'precision': 0.6268939393939393,\n",
       "     'recall': 0.6352956334332834,\n",
       "     'f1-score': 0.6292275104726293,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6048569810252054,\n",
       "     'recall': 0.6074766355140186,\n",
       "     'f1-score': 0.6040475807612843,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None},\n",
       "  {'penalty': 'l2',\n",
       "   'C': 100,\n",
       "   'report': {'Category 1': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.4666666666666667,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5185185185185185,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.5,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6538461538461539,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.693877551020408,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5981308411214953,\n",
       "    'macro avg': {'precision': 0.6007834757834758,\n",
       "     'recall': 0.6213690029985008,\n",
       "     'f1-score': 0.6090136054421769,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5876933727401017,\n",
       "     'recall': 0.5981308411214953,\n",
       "     'f1-score': 0.590927585987666,\n",
       "     'support': 107}},\n",
       "   'model': LogisticRegression(C=100, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   'l1_ratio': None}]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sums = []\n",
    "for cv, ress in results.items():\n",
    "    l = [(cv, res['penalty'], res['C'], res['l1_ratio'], res['report']['macro avg']['precision'] + res['report']['macro avg']['recall'], res['model'], res['report']) for res in ress]\n",
    "    sums.append(sorted(l, key=lambda z: z[4], reverse=True))\n",
    "    \n",
    "best_params = [s[0:3] for s in sums]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('LeaveOneOut',\n",
       "   'l2',\n",
       "   1,\n",
       "   None,\n",
       "   1.3626304136238332,\n",
       "   LogisticRegression(C=1, max_iter=10000, multi_class='multinomial'),\n",
       "   {'Category 1': {'precision': 0.84,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8749999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5483870967741935,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.5396825396825397,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6635514018691588,\n",
       "    'macro avg': {'precision': 0.6720967741935484,\n",
       "     'recall': 0.6905336394302849,\n",
       "     'f1-score': 0.6801857864357863,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6520410009044317,\n",
       "     'recall': 0.6635514018691588,\n",
       "     'f1-score': 0.6567345686504564,\n",
       "     'support': 107}}),\n",
       "  ('LeaveOneOut',\n",
       "   'l2',\n",
       "   1,\n",
       "   None,\n",
       "   1.3626304136238332,\n",
       "   LogisticRegression(C=1, max_iter=10000, multi_class='multinomial', solver='sag'),\n",
       "   {'Category 1': {'precision': 0.84,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8749999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5483870967741935,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.5396825396825397,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6635514018691588,\n",
       "    'macro avg': {'precision': 0.6720967741935484,\n",
       "     'recall': 0.6905336394302849,\n",
       "     'f1-score': 0.6801857864357863,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6520410009044317,\n",
       "     'recall': 0.6635514018691588,\n",
       "     'f1-score': 0.6567345686504564,\n",
       "     'support': 107}}),\n",
       "  ('LeaveOneOut',\n",
       "   'l2',\n",
       "   1,\n",
       "   None,\n",
       "   1.3626304136238332,\n",
       "   LogisticRegression(C=1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   {'Category 1': {'precision': 0.84,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8749999999999999,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5483870967741935,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.5396825396825397,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4727272727272727,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8333333333333333,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6635514018691588,\n",
       "    'macro avg': {'precision': 0.6720967741935484,\n",
       "     'recall': 0.6905336394302849,\n",
       "     'f1-score': 0.6801857864357863,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6520410009044317,\n",
       "     'recall': 0.6635514018691588,\n",
       "     'f1-score': 0.6567345686504564,\n",
       "     'support': 107}})],\n",
       " [('KFold',\n",
       "   'elasticnet',\n",
       "   1,\n",
       "   0.4,\n",
       "   1.1576101903851335,\n",
       "   LogisticRegression(C=1, l1_ratio=0.4, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   {'Category 1': {'precision': 0.8571428571428571,\n",
       "     'recall': 0.782608695652174,\n",
       "     'f1-score': 0.8181818181818182,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.46153846153846156,\n",
       "     'recall': 0.5625,\n",
       "     'f1-score': 0.5070422535211268,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.3870967741935484,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.39999999999999997,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6875,\n",
       "     'recall': 0.4782608695652174,\n",
       "     'f1-score': 0.5641025641025642,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5514018691588785,\n",
       "    'macro avg': {'precision': 0.5983195232187167,\n",
       "     'recall': 0.5592906671664167,\n",
       "     'f1-score': 0.5723316589513773,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.5749703078049475,\n",
       "     'recall': 0.5514018691588785,\n",
       "     'f1-score': 0.5571765692076341,\n",
       "     'support': 107}}),\n",
       "  ('KFold',\n",
       "   'l1',\n",
       "   10,\n",
       "   None,\n",
       "   1.148022294069131,\n",
       "   LogisticRegression(C=10, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='l1', solver='saga'),\n",
       "   {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.42857142857142855,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4477611940298507,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.41379310344827586,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.41379310344827586,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6842105263157895,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.6190476190476191,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5514018691588785,\n",
       "    'macro avg': {'precision': 0.5795604312505401,\n",
       "     'recall': 0.5684618628185907,\n",
       "     'f1-score': 0.5722781387059045,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.557565057503572,\n",
       "     'recall': 0.5514018691588785,\n",
       "     'f1-score': 0.5529177395130984,\n",
       "     'support': 107}}),\n",
       "  ('KFold',\n",
       "   'elasticnet',\n",
       "   10,\n",
       "   1.0,\n",
       "   1.148022294069131,\n",
       "   LogisticRegression(C=10, l1_ratio=1.0, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   {'Category 1': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.42857142857142855,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4477611940298507,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.41379310344827586,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.41379310344827586,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.6842105263157895,\n",
       "     'recall': 0.5652173913043478,\n",
       "     'f1-score': 0.6190476190476191,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.5514018691588785,\n",
       "    'macro avg': {'precision': 0.5795604312505401,\n",
       "     'recall': 0.5684618628185907,\n",
       "     'f1-score': 0.5722781387059045,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.557565057503572,\n",
       "     'recall': 0.5514018691588785,\n",
       "     'f1-score': 0.5529177395130984,\n",
       "     'support': 107}})],\n",
       " [('StratifiedKFold',\n",
       "   'elasticnet',\n",
       "   1,\n",
       "   0.2,\n",
       "   1.3152227972552186,\n",
       "   LogisticRegression(C=1, l1_ratio=0.2, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   {'Category 1': {'precision': 0.875,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8936170212765957,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.4375,\n",
       "     'f1-score': 0.4666666666666667,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4482758620689655,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.4482758620689655,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6481266578249337,\n",
       "     'recall': 0.6670961394302849,\n",
       "     'f1-score': 0.6562215201561181,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6244608195542775,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6286171497829595,\n",
       "     'support': 107}}),\n",
       "  ('StratifiedKFold',\n",
       "   'l2',\n",
       "   1,\n",
       "   None,\n",
       "   1.3138605027843222,\n",
       "   LogisticRegression(C=1, max_iter=10000, multi_class='multinomial', solver='sag'),\n",
       "   {'Category 1': {'precision': 0.875,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8936170212765957,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4838709677419355,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6498214285714285,\n",
       "     'recall': 0.6640390742128935,\n",
       "     'f1-score': 0.6563237516405978,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6268157543391188,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6305931398679959,\n",
       "     'support': 107}}),\n",
       "  ('StratifiedKFold',\n",
       "   'l2',\n",
       "   1,\n",
       "   None,\n",
       "   1.3138605027843222,\n",
       "   LogisticRegression(C=1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   {'Category 1': {'precision': 0.875,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8936170212765957,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5,\n",
       "     'recall': 0.46875,\n",
       "     'f1-score': 0.4838709677419355,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.76,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7916666666666667,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6355140186915887,\n",
       "    'macro avg': {'precision': 0.6498214285714285,\n",
       "     'recall': 0.6640390742128935,\n",
       "     'f1-score': 0.6563237516405978,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6268157543391188,\n",
       "     'recall': 0.6355140186915887,\n",
       "     'f1-score': 0.6305931398679959,\n",
       "     'support': 107}})],\n",
       " [('RepeatedKFold',\n",
       "   'l2',\n",
       "   0.1,\n",
       "   None,\n",
       "   1.432793272066974,\n",
       "   LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial'),\n",
       "   {'Category 1': {'precision': 0.7586206896551724,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8461538461538461,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.6285714285714286,\n",
       "     'recall': 0.6875,\n",
       "     'f1-score': 0.6567164179104478,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5833333333333334,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.5283018867924529,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.8947368421052632,\n",
       "     'recall': 0.7391304347826086,\n",
       "     'f1-score': 0.8095238095238095,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.7009345794392523,\n",
       "    'macro avg': {'precision': 0.7163155734162994,\n",
       "     'recall': 0.7164776986506747,\n",
       "     'f1-score': 0.7101739900951392,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.7014782767424524,\n",
       "     'recall': 0.7009345794392523,\n",
       "     'f1-score': 0.6954791230906685,\n",
       "     'support': 107}}),\n",
       "  ('RepeatedKFold',\n",
       "   'l2',\n",
       "   0.1,\n",
       "   None,\n",
       "   1.3702871852775573,\n",
       "   LogisticRegression(C=0.1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='saga'),\n",
       "   {'Category 1': {'precision': 0.7096774193548387,\n",
       "     'recall': 0.9565217391304348,\n",
       "     'f1-score': 0.8148148148148149,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.6060606060606061,\n",
       "     'recall': 0.625,\n",
       "     'f1-score': 0.6153846153846154,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.625,\n",
       "     'recall': 0.5172413793103449,\n",
       "     'f1-score': 0.5660377358490567,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7894736842105263,\n",
       "     'recall': 0.6521739130434783,\n",
       "     'f1-score': 0.7142857142857143,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6728971962616822,\n",
       "    'macro avg': {'precision': 0.6825529274064928,\n",
       "     'recall': 0.6877342578710646,\n",
       "     'f1-score': 0.6776307200835503,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.67289172687797,\n",
       "     'recall': 0.6728971962616822,\n",
       "     'f1-score': 0.6661375158994627,\n",
       "     'support': 107}}),\n",
       "  ('RepeatedKFold',\n",
       "   'elasticnet',\n",
       "   1,\n",
       "   0.2,\n",
       "   1.3627027489002752,\n",
       "   LogisticRegression(C=1, l1_ratio=0.2, max_iter=10000, multi_class='multinomial',\n",
       "                      penalty='elasticnet', solver='saga'),\n",
       "   {'Category 1': {'precision': 0.875,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8936170212765957,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5714285714285714,\n",
       "     'recall': 0.5,\n",
       "     'f1-score': 0.5333333333333333,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5172413793103449,\n",
       "     'recall': 0.5172413793103449,\n",
       "     'f1-score': 0.5172413793103449,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7307692307692307,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.7755102040816326,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6635514018691588,\n",
       "    'macro avg': {'precision': 0.6736097953770368,\n",
       "     'recall': 0.6890929535232384,\n",
       "     'f1-score': 0.6799254845004766,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6562467905925851,\n",
       "     'recall': 0.6635514018691588,\n",
       "     'f1-score': 0.6584728303729525,\n",
       "     'support': 107}})],\n",
       " [('RepeatedStratifiedKFold',\n",
       "   'elasticnet',\n",
       "   10,\n",
       "   0.4,\n",
       "   1.3749225147041864,\n",
       "   LogisticRegression(C=10, l1_ratio=0.4, max_iter=10000,\n",
       "                      multi_class='multinomial', penalty='elasticnet',\n",
       "                      solver='saga'),\n",
       "   {'Category 1': {'precision': 0.8260869565217391,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8260869565217391,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.59375,\n",
       "     'recall': 0.59375,\n",
       "     'f1-score': 0.59375,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.5384615384615384,\n",
       "     'recall': 0.4827586206896552,\n",
       "     'f1-score': 0.509090909090909,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6728971962616822,\n",
       "    'macro avg': {'precision': 0.6818823160535117,\n",
       "     'recall': 0.6930401986506747,\n",
       "     'f1-score': 0.6863135990562232,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6664270309130123,\n",
       "     'recall': 0.6728971962616822,\n",
       "     'f1-score': 0.668590154838486,\n",
       "     'support': 107}}),\n",
       "  ('RepeatedStratifiedKFold',\n",
       "   'l2',\n",
       "   1,\n",
       "   None,\n",
       "   1.3440897278895114,\n",
       "   LogisticRegression(C=1, max_iter=10000, multi_class='multinomial',\n",
       "                      solver='newton-cg'),\n",
       "   {'Category 1': {'precision': 0.8333333333333334,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.851063829787234,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5806451612903226,\n",
       "     'recall': 0.5625,\n",
       "     'f1-score': 0.5714285714285715,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.4642857142857143,\n",
       "     'recall': 0.4482758620689655,\n",
       "     'f1-score': 0.456140350877193,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7916666666666666,\n",
       "     'recall': 0.8260869565217391,\n",
       "     'f1-score': 0.8085106382978724,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6542056074766355,\n",
       "    'macro avg': {'precision': 0.6674827188940092,\n",
       "     'recall': 0.6766070089955022,\n",
       "     'f1-score': 0.6717858475977178,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6487844007063182,\n",
       "     'recall': 0.6542056074766355,\n",
       "     'f1-score': 0.6512523105337413,\n",
       "     'support': 107}}),\n",
       "  ('RepeatedStratifiedKFold',\n",
       "   'l2',\n",
       "   1,\n",
       "   None,\n",
       "   1.3378103856725483,\n",
       "   LogisticRegression(C=1, max_iter=10000, multi_class='multinomial'),\n",
       "   {'Category 1': {'precision': 0.8076923076923077,\n",
       "     'recall': 0.9130434782608695,\n",
       "     'f1-score': 0.8571428571428572,\n",
       "     'support': 23},\n",
       "    'Category 2': {'precision': 0.5666666666666667,\n",
       "     'recall': 0.53125,\n",
       "     'f1-score': 0.5483870967741935,\n",
       "     'support': 32},\n",
       "    'Category 3': {'precision': 0.48,\n",
       "     'recall': 0.41379310344827586,\n",
       "     'f1-score': 0.4444444444444445,\n",
       "     'support': 29},\n",
       "    'Category 4': {'precision': 0.7692307692307693,\n",
       "     'recall': 0.8695652173913043,\n",
       "     'f1-score': 0.8163265306122449,\n",
       "     'support': 23},\n",
       "    'accuracy': 0.6542056074766355,\n",
       "    'macro avg': {'precision': 0.6558974358974359,\n",
       "     'recall': 0.6819129497751124,\n",
       "     'f1-score': 0.6665752322434351,\n",
       "     'support': 107},\n",
       "    'weighted avg': {'precision': 0.6385286364725616,\n",
       "     'recall': 0.6542056074766355,\n",
       "     'f1-score': 0.6441782420937424,\n",
       "     'support': 107}})]]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
